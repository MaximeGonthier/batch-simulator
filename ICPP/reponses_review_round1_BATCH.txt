% current version: 477 words --- maximum 500

We thank the reviewers and comment on the four major limitations they
identify: 

Motivation:

Our study focuses on a specific setting with mostly genomic
applications, where data is loaded before the computation. We agree
that this may be suboptimal, but this pattern was clearly observed in
the applications used on our platform. Besides, those applications
have very scarce output data compared to the large genomes databases
used as inputs. The study of the trace of the platform leads us to
make these two assumptions.


Simplified model:

- Our model only considers single-node jobs, as they largely prevail
in the studied dataset. However, our scheduler could be extended to
multi-node jobs: scheduling such jobs is a more complex tasks, as one
needs to find several nodes all holding the corresponding data. We
believe studying single-node jobs is a necessary first step, and leave
multi-node jobs for future works.

- Our model does not consider IO contention. We believe that
scheduling IOs to avoid bandwidth contention is an important but
orthogonal task to the present study. We are interested in where to
allocate jobs to reduce IOs, but an additional step may be taken to
better organize unavoidable IOs. Considering both steps
simultaneously would much likely make the model too complex and
intractable.


Lack of competitors and references:

We thank the reviewers for proposing new references, and will include
a subsection on IO optimization in the final version of the
paper. However, we believe these studies are orthogonal to our work:
they all consist in reducing IO contention (through IO pattern
prediction, IO scheduling, etc.) where we try to reduce IOs in the first
place by optimizing job allocation.


Use of simulations:

We agree with the reviewers that simulated results have less impact
than a real implementation. However, it is not possible to deploy a
new scheduling strategy on a real platform (used by numerous
scientists) before demonstrating its usefulness through
simulations. Note that we enroll in the artifact evaluation proposed
by ICPP, and will include all details on the simulator in the artifact description.
	
	
Reviewer 2: The main technical contribution of this work is to study
the effect of data reuse techniques on batch scheduling.

Reviewer 3: We mentioned distributed file systems in our related
work, but we do not consider them as a possible solution: as detailed
above, we concentrate on very large data files that are manually loaded
by applications. Distributed file systems also allow to avoid data
losses in case of failures, which is out-of-scope of our study.
Node-local burst buffers are an interesting solution but simply offer a
new storage space, our approach focusing on data reuse also makes sense
with such burst buffers. Loading a file corresponds to having
it transferred from the file system to the node's cache. 

Reviewer 5: We will provide an appropriate reference for the
stretch metric.
