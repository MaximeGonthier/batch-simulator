\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{diagbox}
\usepackage{colortbl}
\usepackage{pdfpages}
\usepackage{todonotes}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{xcolor,pifont}
\usepackage{fullpage}
\usepackage{algorithm, algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage[english]{babel}
%~ \usepackage[backend=bibtex]{biblatex}
%~ \bibliography{ref_cadre}
\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newtheorem{Problem}{Problem}
\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}
\newtheorem{Hypothesis}{Hypothesis}
\providecommand{\keywords}[1]{\textbf{\textit{Key-words:}} #1}
\newcommand{\LM}[1]{\textcolor{red}{LM:~{#1}}}
\newcommand{\ST}[1]{\textcolor{orange}{ST:~{#1}}}
\newcommand{\TODO}[1]{\textcolor{olive}{TODO:~{#1}}}
\newcommand{\Q}[1]{\textcolor{blue}{Q:~{#1}}}
\setlength{\parskip}{0.2 cm}
\title{Notes articles}
\author{Maxime GONTHIER Samuel THIBAULT Loris MARCHAL}

\newcommand{\card}[1]{\ensuremath{\left|{#1}\right|}\xspace}
\newcommand{\live}{\ensuremath{L}\xspace}
\newcommand{\evict}{\ensuremath{\mathcal{V}}\xspace}
\newcommand{\dataset}{\ensuremath{\mathbb{D}}\xspace}
\newcommand{\taskset}{\ensuremath{\mathbb{T}}\xspace}
\newcommand{\packageset}{\ensuremath{\mathbb{P}}\xspace}
\newcommand{\inputs}{\ensuremath{\mathcal{D}}\xspace}
\newcommand{\optpb}{\textsc{Min\-Loads\-For\-Tasks\-Sharing\-Data}\xspace}
\newcommand{\nbloads}{\ensuremath{\mathit{\mathit{\#Loads}}}\xspace}
\newcommand{\MIN}{\ensuremath{\mathit{MIN}}\xspace}
\newcommand{\starpu}{\textsc{StarPU}\xspace}
\newcommand{\nbPU}{\ensuremath{\vert PU \vert}\xspace}

\usepackage{tikz}
\usetikzlibrary{fit, shapes.geometric, patterns}

\makeatletter\tikzset{hatch distance/.store in=\hatchdistance,hatch distance=5pt,hatch thickness/.store in=\hatchthickness,hatch thickness=5pt}\pgfdeclarepatternformonly[\hatchdistance,\hatchthickness]{north east hatch}{\pgfqpoint{-1pt}{-1pt}}{\pgfqpoint{\hatchdistance}{\hatchdistance}}{\pgfpoint{\hatchdistance-1pt}{\hatchdistance-1pt}}{\pgfsetcolor{\tikz@pattern@color}\pgfsetlinewidth{\hatchthickness}\pgfpathmoveto{\pgfqpoint{0pt}{0pt}}\pgfpathlineto{\pgfqpoint{\hatchdistance}{\hatchdistance}}\pgfusepath{stroke}}\makeatother\usetikzlibrary{calc,shadings,patterns,tikzmark}\newcommand\HatchedCell[5][0pt]{\begin{tikzpicture}[overlay,remember picture]\path ($(pic cs:#2)!0.5!(pic cs:#3)$)coordinate(aux1)(pic cs:#4)coordinate(aux2);\fill[#5]($(aux1)+(-0.23*0.075\textwidth,1.9ex)$)rectangle($(aux1 |- aux2)+(0.23*0.075\textwidth,-#1*\baselineskip-.8ex)$);\end{tikzpicture}}

\newcounter{nodemarkers}
\newcommand\circletext[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-\arabic{nodemarkers}-a) at (0,1.5ex) {};%
    #1%
    \tikz[overlay,remember picture]
        \node (marker-\arabic{nodemarkers}-b) at (0,0){};%
    \tikz[overlay,remember picture,inner sep=2pt]
        \node[draw,ellipse,fit=(marker-\arabic{nodemarkers}-a.center) (marker-\arabic{nodemarkers}-b.center)] {};%
    \stepcounter{nodemarkers}%
}

% Pour les checkmark
\newcommand*\colourcheck[1]{%
  \expandafter\newcommand\csname #1check\endcsname{\textcolor{#1}{\ding{52}}}
}
\colourcheck{green}
\newcommand{\ok}[1]{\textcolor{ForestGreen}{OK \greencheck}}
\newcommand{\oktext}[1]{\textcolor{ForestGreen}{OK \greencheck}~\textcolor{ForestGreen}{#1}}

\begin{document}
\newpage

%~ /data-aware-batch-scheduling/MBSS$ oarsub -p orion -l core=2,walltime=08:00:00 -r '2022-06-14 19:00:00' "bash Stats_single_workload.sh inputs/workloads/converted/test-11 inputs/clusters/rackham_450_128_32_256_4_1024.txt Fcfs 0"

\section{Informations for the article}
	\begin{enumerate}
		\item HEFT is like fcfs with a score x1 x0 x0 x0
		\item Use same X scale for some gantt charts when I want to compare them: to do that add a job of duration 0 at the maxtime of the heuristic you are showing
		\item Faire plusieurs test et mettre une barre d'erreur (ce qui varie c'est la taille des fichiers d'entrées lors de la génération du workload). For this I did Generate\_workload\_from\_rackham\_for\_variance.sh to generate different workloads (10 is enough or I go up to 30 ? Might take a while if I do 30 times the same test. Or maybe just once to show the varaince is small ?) and then I try them all and show the variance.
		\item Use same X scale for workloads stats when I want to compare them
		\item cluster usage in real: https://www.uppmax.uu.se/resources/system-usage/rackham/
		\item About files in the simulation: %\url{https://webmail.ens-lyon.fr/?_task=mail&_caps=pdf%3D1%2Cflash%3D0%2Ctif%3D0&_uid=5368&_mbox=INBOX&_action=show}
	 \end{enumerate}

\section{What's new since last meeting ?}

	\begin{enumerate}
		% Pour elisabeth et carl
		\item Re-writing of area filling
		\item More heatmaps fcfs with a score and all multipliers combination heatmaps
		\item Code area filling ratio and area filling omniscient
		\item pseudo code area filling with different filling of allocated area (It's: Allocated Area[choosen size][x] gets Allocated Area[choosen size][x] + Area(Ji) with Area(Ji) = cores*walltime. But I would prefer to do: cores*(delay+transfer time))
		\item code area filling with ratio and allocated area
		\item code easybf fcfs only
		\item are filling omnisicnet comme je fais en ce moment. Si ca marche pas essayer avec le graduellement
		\item dans area filling: A la place de immedialy est ce que ca finir a plus tot sur le noeud de taille x + 1 et comparer aussi avec x + 2 ... x + n.
		\item Size constraint: sorting by size is bad if normal cluster
		\item ignore dt for constraint == 2
		\item revoir area filling tart dans le main en fct de planned or ratio et des nouveau noms de fichiers et retester avec les 2 cluster différents.
		\item plot with nb of upgraded jobs
		\item plot avec backfill. Ameliore fcfs mais fcfs score est meilleur sans. La diff e transfert est grande entre fcfs score et fcfs score bf
		\item Why are filling so bad ? Even in omniscient ? I corrected a bit but it's still worse. Also there is a difference between true allocated area and the one I compute in the schedule (because the scheduele change and I only update allocated area when a job start. Else I have a temp one just for the current schedule).
		\item Try in area filling to reduce allocated area by the diff between walltime and real delay if the job finished before it's walltime
		\item Comment one paper of vincenc
		\item Mail au gars de data locality sur numa: Jannis Klinkenberg
		\item dossier inscription administrative
		\item attestation sur siged de acaces et IPDPS
		\item plot the number of jobs where the queue time is superior to 25000 for example
		\item tirer quelques conclusions dans le document principal
		\item plot 2 contraintes ensembles
		\item code pour tracer terminaison des jobs -2 sur courbes usage du cluster: mais toujours pas full. Je devrais prendre bcp plus loin dans le futur ?
		\item tester en faisant varier le multiplicateur de fcfs score area filling: je n'observe pas d'améliorations
		\item Afficher temps de transferts sur les Gantt charts
		
		% Reu du 29/08
		\item Pour le workload: ignorer jobs cancelled. Ne pas ignorer job failed ou timeout. Si jobs multi node les diviser. Ajout d'un overhead de 2*1min aux jobs et de 1*2min aux failed. Data sur tous les jobs.
		\item stats sur workload can be plotted
		\item cluster usage is good now
		\item temporalité des gros jobs en terme de submit time
		\item looking at further jobs for workload but not adding them in my schedule if after day2 (14 jours entier et couper pour voir si on a vraiment tout)
		\item ré ecriture des algos fcfs score + backfill big nodes or + area filling
		\item new plots size constraint only
		\item code backfill 95th percentile: trop de complexité car je regarde tout les noeuds

		% Reu du 06/09
		\item voir fonctionnement area filling ratio en détail: penser a update allocated area dans start et end jobs pour les nouveaux algo area filing
		\item Je prendres une semaine plus tôt pour recup les planned and ratio area en cas non omniscient
		\item Je prends 1 mois entier dans le passé pour ratio area
		\item Ré écriture strat backfill 3
		\item code backfill strat 2 et vérifié
		\item code backfill strat 1 corrigé et vérifié
		\item code area filling strat 1 vérifié
		\item code area filling strat 2 et 2bis et vérifié
		\item new plot size constraint pour non omniscient: not shown but we are also better in total flow and total queue time
		\item code backfill start 3 et vérifié
		\item plot size and data constraint. certains algo pas montré car trop long a faire tourner. Le pb de fcfs avec un score est que dans certains cas les multiplicateurs anulle totalement la possiblité d'upgrade des jobs! Ils ne sont pas constant avec les different workloads. Le score l'emporte sur l'upgrade.
		
		% Reu FGCS
		\item Citation QR-heft-tmdp-pr dans réponse au reviewer 2
		\item Revoir parla et optimal locality scheduling et refaire dans les related works
		\item expliquer sparse dans settings
	\end{enumerate}
	
\section{Questions for next meeting}
	\begin{enumerate}
		\item Garder N en abscisse des courbes sparses ?
		\item J'ai enlevé des random order HFP les sous paquets de la visu et des explications. Est-ce toujours facile à comprendre (en bas de la page 17) ?
		\item 4 figures en 1. Peut etre enlever les points et mettre un trait plus large ?
		\item Pour les courbes par 4 on peut aussi le faire avec 3D/3D simu/3D DT/Cholesky
	\end{enumerate}
	
\section{Todo}
	\subsection{General}
		\begin{enumerate}
			\item se renseigner payement enseirb semestre 1: attendre octobre
			\item payer ré inscription: déposer le dossier de l'écolde doctorale sur siged recap
			\item Répondre a Bora
			\item transmettre dossier siged  et payer une fois tous les avis saisies (5/6 ou 6/6)
		\end{enumerate}
	\subsection{FGCS}
		\begin{enumerate}
			\item j'ai trouvé des articles qui parle de gemm/cholesky comme c'est dans chameleon. Les citer et parler de DMDAR comme state of the art result from chameleon gemm/cholesky ? Le renommer partout dans les textest et courbes ou seulement le mentionner ? (appeller dmdar comme un state of the art result pour le produit de matrice l'appeller "chameleon gemm" et citer un papier chamelon et son noyau gemm): le présenter comme ordo par défaut de chameleon (utilisé par airbus) (qui est dmdas sans prio et le r ajoute la localité)
			\item Faut-il mettre les ref de ce qu'on a ajouté come citation dans les réponses aux reviewers ? pas pour tout mais globalement oui mais plus rapidement
			\item Reviewer 1 demande à propos du multi GPU ? On cite le papier d'ipdps ou on parle de mHFP ?
			\item les questions du reviewers 1, est-ce que les réponses doivent aussi aparaitre dans l'article ? Notamment quand il dit "must better justify the benchmark selection" et "This may not be a problem if the article clearly explain the experimental methodology"
			\item expliquer ce qu'on vois sur les captions de toutes les visualisations: je ne l'ai fais que pour la première figure du genre
			\item refaire toutes les visu avec nouvelles couleurs et sans ligne noires HFP puis les metres cote a cote
			\item Refaire le dépôt, attention enlever les define print des 4 schedulers queje visualise et revoir script r par raport ax chemins et ajouter script r 4 panel si utilisé
			\item dernière question: il faut du recouvrement, taille classiquement choisi (cité un truc ?)
			\item vérifier les "s"
			\item revierwer 2.1: y en a pour les cu, et peuvent etre utilisé (exemple ref1 de mst)
			\item Reviewer 2. fin de page 4, on a state of the art dmdar
			\item dans l'abstract clarifié le 1GPU et répondre au reviewer en parlant de future work
			\item concurrent: starpu le permet mais pas pertinent sur ces app.
			\item multi gpu: future work
			\item réponse DAG: ni l'un ni l'autres c'est un bit, la on a juste des taches
			\item citation en footnote pour answer si on parle d'un papieren particulier. Parla par ex
			\item mettre fig 18 19 visu cote a cote
			\item insérer les figures sparses
			\item regarder hdr sam pour biblio runtimes
			\item reviewer 1 point 3: expliquer ce qui existe (heft etc...) dmda lui prend en compte la localité en plus de heft donc on se compare a lui. Peu de runtime font de la localité automatiquement, on ne veux pas flag a la main les data a re utilisé.
		\end{enumerate}
	\subsection{Uppsala}
		\begin{enumerate}
			\item faire 2 workloads, 1 chargé et 1 non et tester Fcfs et Fcfs with a score. Si fcfs with a score s'en sort mal en cluster vide, il faut des multiplicateurs qui s'adaptent. et tester avec EATx500 ?? Non je pense pas pour ce dernier point.
			\item tester multiplicateur pour area factor
			\item ajouter bf a tous et retester ?
			\item corriger histogrammes stats workloads
			\item tester avec data sur jobs de plus de 5 cores seulement
			\item regarder qui sont les jobs delaier de plus de 25000
			\item test autres workloads pour les 2 contraintes
			\item mettre a jour planned area pour fcfs score area filling quand j'upgrade des jobs ?
			\item generation de workload : aller chercher loin puis cut le fichier plus tôt pour pas avoir trop de jobs non plus ?
			\item Ne pas oublier que j'ai les courbes VS sur flow stretch et queue times aussi que je peux tracer						
		\end{enumerate}
\end{document}
