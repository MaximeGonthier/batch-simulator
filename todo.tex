\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{diagbox}
\usepackage{colortbl}
\usepackage{pdfpages}
\usepackage{todonotes}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{xcolor,pifont}
\usepackage{fullpage}
\usepackage{algorithm, algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage[english]{babel}
%~ \usepackage[backend=bibtex]{biblatex}
%~ \bibliography{ref_cadre}
\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newtheorem{Problem}{Problem}
\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}
\newtheorem{Hypothesis}{Hypothesis}
\providecommand{\keywords}[1]{\textbf{\textit{Key-words:}} #1}
\newcommand{\LM}[1]{\textcolor{red}{LM:~{#1}}}
\newcommand{\ST}[1]{\textcolor{orange}{ST:~{#1}}}
\newcommand{\TODO}[1]{\textcolor{olive}{TODO:~{#1}}}
\newcommand{\Q}[1]{\textcolor{blue}{Q:~{#1}}}
\setlength{\parskip}{0.2 cm}
\title{Notes articles}
\author{Maxime GONTHIER Samuel THIBAULT Loris MARCHAL}

\newcommand{\card}[1]{\ensuremath{\left|{#1}\right|}\xspace}
\newcommand{\live}{\ensuremath{L}\xspace}
\newcommand{\evict}{\ensuremath{\mathcal{V}}\xspace}
\newcommand{\dataset}{\ensuremath{\mathbb{D}}\xspace}
\newcommand{\taskset}{\ensuremath{\mathbb{T}}\xspace}
\newcommand{\packageset}{\ensuremath{\mathbb{P}}\xspace}
\newcommand{\inputs}{\ensuremath{\mathcal{D}}\xspace}
\newcommand{\optpb}{\textsc{Min\-Loads\-For\-Tasks\-Sharing\-Data}\xspace}
\newcommand{\nbloads}{\ensuremath{\mathit{\mathit{\#Loads}}}\xspace}
\newcommand{\MIN}{\ensuremath{\mathit{MIN}}\xspace}
\newcommand{\starpu}{\textsc{StarPU}\xspace}
\newcommand{\nbPU}{\ensuremath{\vert PU \vert}\xspace}

\usepackage{tikz}
\usetikzlibrary{fit, shapes.geometric, patterns}

\makeatletter\tikzset{hatch distance/.store in=\hatchdistance,hatch distance=5pt,hatch thickness/.store in=\hatchthickness,hatch thickness=5pt}\pgfdeclarepatternformonly[\hatchdistance,\hatchthickness]{north east hatch}{\pgfqpoint{-1pt}{-1pt}}{\pgfqpoint{\hatchdistance}{\hatchdistance}}{\pgfpoint{\hatchdistance-1pt}{\hatchdistance-1pt}}{\pgfsetcolor{\tikz@pattern@color}\pgfsetlinewidth{\hatchthickness}\pgfpathmoveto{\pgfqpoint{0pt}{0pt}}\pgfpathlineto{\pgfqpoint{\hatchdistance}{\hatchdistance}}\pgfusepath{stroke}}\makeatother\usetikzlibrary{calc,shadings,patterns,tikzmark}\newcommand\HatchedCell[5][0pt]{\begin{tikzpicture}[overlay,remember picture]\path ($(pic cs:#2)!0.5!(pic cs:#3)$)coordinate(aux1)(pic cs:#4)coordinate(aux2);\fill[#5]($(aux1)+(-0.23*0.075\textwidth,1.9ex)$)rectangle($(aux1 |- aux2)+(0.23*0.075\textwidth,-#1*\baselineskip-.8ex)$);\end{tikzpicture}}

\newcounter{nodemarkers}
\newcommand\circletext[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-\arabic{nodemarkers}-a) at (0,1.5ex) {};%
    #1%
    \tikz[overlay,remember picture]
        \node (marker-\arabic{nodemarkers}-b) at (0,0){};%
    \tikz[overlay,remember picture,inner sep=2pt]
        \node[draw,ellipse,fit=(marker-\arabic{nodemarkers}-a.center) (marker-\arabic{nodemarkers}-b.center)] {};%
    \stepcounter{nodemarkers}%
}

% Pour les checkmark
\newcommand*\colourcheck[1]{%
  \expandafter\newcommand\csname #1check\endcsname{\textcolor{#1}{\ding{52}}}
}
\colourcheck{green}
\newcommand{\ok}[1]{\textcolor{ForestGreen}{OK \greencheck}}
\newcommand{\oktext}[1]{\textcolor{ForestGreen}{OK \greencheck}~\textcolor{ForestGreen}{#1}}

\begin{document}

%~ \tableofcontents
\newpage

\section{What's new since last meeting ?}

	\begin{enumerate}
		\item Try with 900 seconds time frame for consecutive jobs sharing a file to see what happens. Seems to work well because with much more I get the same number of different data.
		\item Code and script to get stats on workload used (cores asked and used, node used, scheduled job, walltime and delay)
		\item Change percentage of task with 256 or 1024 files to 80/10/5
		\item Cluster usage with 5 consecutive days. For more (7 and 10 days) it starts to be too long to compute.
		\item Plots fcfs score multiplier and fcfs score with malus on nb of copy
		\item Try fcfs with a score new variant: add penalty the more a file is loaded on other nodes
		\item Play with multiplier of fcfs with a score
		\item New ideas on big nodes variant
	\end{enumerate}
	
\section{Questions for next meeting}

	\begin{enumerate}
		\item The formula foir the score is: $score = earliest_available_time + multiplier*time_to_load_file + multiplier*time_to_reload_evicted_files + nb_copy_file_to_load*time_to_load_file*multiplier_nb_copy$. I separate time to load and number of copy because for the first one I consider the case of parallel load, not for the other one where if a load started, I consider the file to be on the node and thus do not put a malus for this node. So the multiplier can be different for transfer and copy Is it correct ?
		\item Which question can I be asked at the conference ?
		\item Common file packages with a score: change name of result of division because it's more a ratio. Try to distribute divide packages differently. Maybe get the share of the platform needed ? Do a figure to help.
		\item How can I add the walltime in the score y of variant of bacfilling big nodes ?
		\item How to incorporate my strategie on sizes constraint into other algorithms than FCFS ?
		\item Speech flow of task
		\item Speech expliquer dense outer ? AxB ? C += AxB ?
		\item Slide 15 que dire ?
		\item Volontaire
		\item Different results if full cluster or reduced one because the time frame is really full on the reduced cluster
	\end{enumerate}

\section{Todo}
	\subsection{General}
		\begin{enumerate}	
			\item Test strats constraint on sizes
			\item Pas besoin de sort la liste de job par tailles a chaque fois je peux juste insérr les nouveaux jobs en bas de chaque sous liste de jobs par tailles
			\item Apply bignodes backfill to fcfs with a score
			\item test with full cluster multiplier on nb of copy
			\item Problem of different nodes sizes requirmeent: Ok I can try. for the varaint add to the score the walltime of the job because you don't want to occupy too much a big node. Test this idea with data but with no constraint on data locality, so ignore transfer time (remove files in the workload for this) and see the results. Need to produce workload with 0 files but constraint on sizes. Or just ignore transfers.
			\item Préparer présentation le 18
			\item S'inscrire a ACACES
			\item Billets d'avion BOD-FUI NPL-BOD
			\item Se ré-inscrire à l'ENS avant le 15 Juin
			\item Faire slides + longues pour Fréjus
			\item Envoyer abstract ACACES avant 15 juin
			\item Faire poster ACACES
			\item Budget ACACES
			\item plots same stats with real data used from rackham history decision
			\item Rendre général le modèle des coeurs et des mémoires et des tailles des fichiers. Pour ce dernier chaque job a un fichier d'une certaine taille. Dans mo cas particulier la taille est un multiple de la taille de la mémoire des noeuds. Ensuite décrire la plateforme précise que j'utilise mais avant rendre le cas général. Décrire la plateforme au moment expé.
			\item Cours pour l'année prochaine
			\item Après avis favorable déposer dossier sur SIGED
			\item Elongation: multiply each submission time by a constant
			\item Idea algo: 6.2 + penalty for fcfs + easybf or conservative bf
			\item Refelchir a maximum use en mieux
			\item faire des boxplots
			\item faire option easy bf a la place de shceuler en particulier
			\item Voir thèses de Herman
			\item Talk to Hans Karlsson
			\item Lire articles Emanuel Rubensson \url{https://webmail.ens-lyon.fr/?_task=mail&_caps=pdf%3D1%2Cflash%3D0%2Ctif%3D0&_uid=4630&_mbox=INBOX&_action=show}
			\item Compare algo with different workloads. Use queue time of each job compared to a baseline. Compare queue time of each job between 2 heuristics by saying who won on each queue time.
			\item Code to compare ourselves, HEFT that would be FCFS that take into consideration transfer time for the earliest available cores
			\item Use same X scale for distributions of queue times
			\item Use same X scale workloads stats
			\item Use same X scale for some gantt charts when I want to compare them
			\item Code algo 2
			\item vidéo IPDPS avant le 15 mai
			\item TODO du code: backfill, available node list qui contient les cores available aussi
			\item contrainte de la localié sur la taille de la données, contrainte sur les coeurs, contrainte sur les partage de données
			\item stratégie qui essaye d'utiliser moins les gros noeud pour les garder pour les gros jobs ?
			\item Lors d'une exec imprimer sur le terminal et dans le fichier de résultats les stats sur le workload et le cluster
			\item Comparer algo qui reschedule tout et algo qui schedule que quand un nouveau core est disponible et ne schedule que 1 seul job a la fois par cores.
			\item lire article bf : Utilization, Predictability, Workloads
			\item Faire plusieurs test et mettre une barre d'erreur
			\item Afficher temps de transferts sur les Gantt charts
		\end{enumerate}
	\subsection{Batsim}
		\begin{enumerate}
			\item Batsim a pas la granularité au sein d'un noeud
			\item Gérer n nodes
			\item Gérer n jobs
			\item Faire un delay aussi long que la somme du poids des données manquantes
			\item faire la maj des données du node partout, sois Dans le scheduler sois dans fit mais faut le faire!
			\item Gérér à la main les évictions
		\end{enumerate}

\end{document}
