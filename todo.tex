\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{diagbox}
\usepackage{colortbl}
\usepackage{pdfpages}
\usepackage{todonotes}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{xcolor,pifont}
\usepackage{fullpage}
\usepackage{algorithm, algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage[english]{babel}
%~ \usepackage[backend=bibtex]{biblatex}
%~ \bibliography{ref_cadre}
\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newtheorem{Problem}{Problem}
\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}
\newtheorem{Hypothesis}{Hypothesis}
\providecommand{\keywords}[1]{\textbf{\textit{Key-words:}} #1}
\newcommand{\LM}[1]{\textcolor{red}{LM:~{#1}}}
\newcommand{\ST}[1]{\textcolor{orange}{ST:~{#1}}}
\newcommand{\TODO}[1]{\textcolor{olive}{TODO:~{#1}}}
\newcommand{\Q}[1]{\textcolor{blue}{Q:~{#1}}}
\setlength{\parskip}{0.2 cm}
\title{Notes articles}
\author{Maxime GONTHIER Samuel THIBAULT Loris MARCHAL}

\newcommand{\card}[1]{\ensuremath{\left|{#1}\right|}\xspace}
\newcommand{\live}{\ensuremath{L}\xspace}
\newcommand{\evict}{\ensuremath{\mathcal{V}}\xspace}
\newcommand{\dataset}{\ensuremath{\mathbb{D}}\xspace}
\newcommand{\taskset}{\ensuremath{\mathbb{T}}\xspace}
\newcommand{\packageset}{\ensuremath{\mathbb{P}}\xspace}
\newcommand{\inputs}{\ensuremath{\mathcal{D}}\xspace}
\newcommand{\optpb}{\textsc{Min\-Loads\-For\-Tasks\-Sharing\-Data}\xspace}
\newcommand{\nbloads}{\ensuremath{\mathit{\mathit{\#Loads}}}\xspace}
\newcommand{\MIN}{\ensuremath{\mathit{MIN}}\xspace}
\newcommand{\starpu}{\textsc{StarPU}\xspace}
\newcommand{\nbPU}{\ensuremath{\vert PU \vert}\xspace}

\usepackage{tikz}
\usetikzlibrary{fit, shapes.geometric, patterns}

\makeatletter\tikzset{hatch distance/.store in=\hatchdistance,hatch distance=5pt,hatch thickness/.store in=\hatchthickness,hatch thickness=5pt}\pgfdeclarepatternformonly[\hatchdistance,\hatchthickness]{north east hatch}{\pgfqpoint{-1pt}{-1pt}}{\pgfqpoint{\hatchdistance}{\hatchdistance}}{\pgfpoint{\hatchdistance-1pt}{\hatchdistance-1pt}}{\pgfsetcolor{\tikz@pattern@color}\pgfsetlinewidth{\hatchthickness}\pgfpathmoveto{\pgfqpoint{0pt}{0pt}}\pgfpathlineto{\pgfqpoint{\hatchdistance}{\hatchdistance}}\pgfusepath{stroke}}\makeatother\usetikzlibrary{calc,shadings,patterns,tikzmark}\newcommand\HatchedCell[5][0pt]{\begin{tikzpicture}[overlay,remember picture]\path ($(pic cs:#2)!0.5!(pic cs:#3)$)coordinate(aux1)(pic cs:#4)coordinate(aux2);\fill[#5]($(aux1)+(-0.23*0.075\textwidth,1.9ex)$)rectangle($(aux1 |- aux2)+(0.23*0.075\textwidth,-#1*\baselineskip-.8ex)$);\end{tikzpicture}}

\newcounter{nodemarkers}
\newcommand\circletext[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-\arabic{nodemarkers}-a) at (0,1.5ex) {};%
    #1%
    \tikz[overlay,remember picture]
        \node (marker-\arabic{nodemarkers}-b) at (0,0){};%
    \tikz[overlay,remember picture,inner sep=2pt]
        \node[draw,ellipse,fit=(marker-\arabic{nodemarkers}-a.center) (marker-\arabic{nodemarkers}-b.center)] {};%
    \stepcounter{nodemarkers}%
}

% Pour les checkmark
\newcommand*\colourcheck[1]{%
  \expandafter\newcommand\csname #1check\endcsname{\textcolor{#1}{\ding{52}}}
}
\colourcheck{green}
\newcommand{\ok}[1]{\textcolor{ForestGreen}{OK \greencheck}}
\newcommand{\oktext}[1]{\textcolor{ForestGreen}{OK \greencheck}~\textcolor{ForestGreen}{#1}}

\begin{document}

%~ \tableofcontents
\newpage

\section{What's new since last meeting ?}

	\begin{enumerate}
		\item Correction on walltimes conversion. Need to redo test and now it's much longer because the cluster is really used.
		\item Try with 900 seconds time frame for consecutive jobs sharing a file to see what happens. Seems to work well because with much more I get the same number of different data.
		\item Code and script to get stats on workload used (cores asked and used, node used, scheduled job, walltime and delay)
		\item Change percentage of task with 256 or 1024 files to 80/10/5
		\item Cluster usage with 5 consecutive days. For more (7 and 10 days) it starts to be too long to compute.
		\item Try fcfs with a score new variant: add penalty the more a file is loaded on other nodes
		\item Play with multiplier of fcfs with a score
		\item New ideas on big nodes variant
		\item Prendre que les jobs des jours sélectionés en utilisant la premiere ligne du raw avec vrai temps et starttime qui donne le temps du jour
		\item New application name in slides. What do you think ? If it's ok I'll change the name in the slides' title as well?
	\end{enumerate}
	
\section{Questions for next meeting}

	\begin{enumerate}
		\item The formula foir the score is: $score = earliest\_available\_time + multiplier*time\_to\_load\_file + multiplier*time\_to\_reload\_evicted\_files + nb\_copy\_file\_to\_load*time\_to\_load\_file*multiplier\_nb\_copy$. I separate time to load and number of copy because for the first one I consider the case of parallel load, not for the other one where if a load started, I consider the file to be on the node and thus do not put a malus for this node. So the multiplier can be different for transfer and copy. Is it correct ?
		\item Which question can I be asked at the conference ?
		\item Common file packages with a score: change name of result of division because it's more a ratio. Try to distribute divide packages differently. Maybe get the share of the platform needed ? Do a figure to help: call it nb cores asked. Préciser que le point b donne le i avec i = 0 ou $J_i$. Le i de paquets est pas le même. On peut pas comparer une proportion avec un nombre. Pas utile de diviser par nb de coeurs du cluster. Il faut regarder quand c'est plus grand. Mettre 1 coeur par job. Calculer nb de coeurs total demandé. uand je prens un packets pour lui je calcule le nb de noeud que je veux lui dedier. Je prends le (nb de coeur demandé par le paquet en question*nb de ceurs disponible sur la plateforme) / total de nb de nodes demandé par tous les paquets. arrondi a au moins 1.
		\item How can I add the walltime in the score y of variant of bacfilling big nodes ?
		\item How to incorporate my strategy on sizes constraint into other algorithms than FCFS ?
		\item Speech flow of task: Expliquer le cadre gris car on ne peut pas toucher au gris. On met un certain nombre de tache dans le buffer, peut faire du prefetch. Un certain nombre pour recouvrir le prefetch. Puis la premiere en donné au gpu. Dire que ya 2 etapes distinctes dans les buffers. 
		\item Speech expliquer dense outer ? AxB ? C += AxB ? A la slide 13 dire C = AxB, A = LLt pour cholesky Et dire A et b a charger pour calculer C. Prendre le temps sur la slide 14
		\item Volontaire
		\item Different results if full cluster or reduced one because the time frame is really full on the reduced cluster. It's not the true behavior with reduce cluster because users would act differently.
		\item Can I reduce complexity by not scheduling everything ? But how without altering th schedule ?
		\item python3 is actually faster ?
	\end{enumerate}

\section{Todo}
	\subsection{General}
		\begin{enumerate}
			\item reduire complexité
			\item re tester avec workload corrigées full et 5 jours
			\item re tester avec workload corrigées 1 jour et cluster réduit
			\item test fcfs score
			\item test big nodes strats
			\item decaler orignie au premier jour pris en compte pour les figures utilisation du cluster
			\item Compter le nb de coeurs demandé par les jobs et compter pendant pendant l'execution combien de coeurs j'ai a la date 16
			\item prendre les jobs d'avant et les tronquer du temps t du 16 sur leurs walltime et delay et les schedule pour de vrai avec le vrai historique en prenant la vrai date de demarrage et le noeuds. Ceux qui traverse pas el 16 ils prennent le vrai historique. Ceux qui traverse sur le 16 je les reschedule avec mon algo avant les autres jobs mais seulement leurs partie tronqués. Puis apres je lance mon algo sur les jobs soumis le 16.
			\item Afficher date sur graphe d'utilisation du cluster.
			\item tracer sous courbe usage nb de soumissions de jobs par jours cumulées
			\item reecrire common
			\item divise aire des job par aire des noeuds. Donne une proportion par laquelle on peut augmenter le walltime.
			\item Essayer de ne pas tout schedule a l'avance pour réduire la complexité
			\item profiler mon code pour voir ce qui coute du temps
			\item prendre jours du 14 au 20 pour voir
			\item vrai subfigure dans le pdf
			\item Test strats constraint on sizes
			\item Pas besoin de sort la liste de job par tailles a chaque fois je peux juste insérr les nouveaux jobs en bas de chaque sous liste de jobs par tailles
			\item Apply bignodes backfill to fcfs with a score
			\item test with full cluster multiplier on nb of copy
			\item Problem of different nodes sizes requirmeent: Ok I can try. for the varaint add to the score the walltime of the job because you don't want to occupy too much a big node. Test this idea with data but with no constraint on data locality, so ignore transfer time (remove files in the workload for this) and see the results. Need to produce workload with 0 files but constraint on sizes. Or just ignore transfers.
			\item Préparer présentation le 18
			\item S'inscrire a ACACES
			\item Billets d'avion BOD-FUI NPL-BOD
			\item Se ré-inscrire à l'ENS avant le 15 Juin
			\item Faire slides + longues pour Fréjus
			\item Envoyer abstract ACACES avant 15 juin
			\item Faire poster ACACES
			\item Budget ACACES
			\item plots same stats with real data used from rackham history decision
			\item Rendre général le modèle des coeurs et des mémoires et des tailles des fichiers. Pour ce dernier chaque job a un fichier d'une certaine taille. Dans mo cas particulier la taille est un multiple de la taille de la mémoire des noeuds. Ensuite décrire la plateforme précise que j'utilise mais avant rendre le cas général. Décrire la plateforme au moment expé.
			\item Cours pour l'année prochaine
			\item Après avis favorable déposer dossier sur SIGED
			\item Elongation: multiply each submission time by a constant
			\item Idea algo: 6.2 + penalty for fcfs + easybf or conservative bf
			\item Refelchir a maximum use en mieux
			\item faire des boxplots
			\item faire option easy bf a la place de shceuler en particulier
			\item Voir thèses de Herman
			\item Talk to Hans Karlsson
			\item Lire articles Emanuel Rubensson \url{https://webmail.ens-lyon.fr/?_task=mail&_caps=pdf%3D1%2Cflash%3D0%2Ctif%3D0&_uid=4630&_mbox=INBOX&_action=show}
			\item Compare algo with different workloads. Use queue time of each job compared to a baseline. Compare queue time of each job between 2 heuristics by saying who won on each queue time.
			\item Code to compare ourselves, HEFT that would be FCFS that take into consideration transfer time for the earliest available cores
			\item Use same X scale for distributions of queue times
			\item Use same X scale workloads stats
			\item Use same X scale for some gantt charts when I want to compare them
			\item Code algo 2
			\item vidéo IPDPS avant le 15 mai
			\item TODO du code: backfill, available node list qui contient les cores available aussi
			\item contrainte de la localié sur la taille de la données, contrainte sur les coeurs, contrainte sur les partage de données
			\item stratégie qui essaye d'utiliser moins les gros noeud pour les garder pour les gros jobs ?
			\item Lors d'une exec imprimer sur le terminal et dans le fichier de résultats les stats sur le workload et le cluster
			\item Comparer algo qui reschedule tout et algo qui schedule que quand un nouveau core est disponible et ne schedule que 1 seul job a la fois par cores.
			\item lire article bf : Utilization, Predictability, Workloads
			\item Faire plusieurs test et mettre une barre d'erreur
			\item Afficher temps de transferts sur les Gantt charts
		\end{enumerate}
	\subsection{Batsim}
		\begin{enumerate}
			\item Batsim a pas la granularité au sein d'un noeud
			\item Gérer n nodes
			\item Gérer n jobs
			\item Faire un delay aussi long que la somme du poids des données manquantes
			\item faire la maj des données du node partout, sois Dans le scheduler sois dans fit mais faut le faire!
			\item Gérér à la main les évictions
		\end{enumerate}

\end{document}
