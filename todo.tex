\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{diagbox}
\usepackage{colortbl}
\usepackage{pdfpages}
\usepackage{todonotes}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{xcolor,pifont}
\usepackage{fullpage}
\usepackage{algorithm, algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage[english]{babel}
%~ \usepackage[backend=bibtex]{biblatex}
%~ \bibliography{ref_cadre}
\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newtheorem{Problem}{Problem}
\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}
\newtheorem{Hypothesis}{Hypothesis}
\providecommand{\keywords}[1]{\textbf{\textit{Key-words:}} #1}
\newcommand{\LM}[1]{\textcolor{red}{LM:~{#1}}}
\newcommand{\ST}[1]{\textcolor{orange}{ST:~{#1}}}
\newcommand{\TODO}[1]{\textcolor{olive}{TODO:~{#1}}}
\newcommand{\Q}[1]{\textcolor{blue}{Q:~{#1}}}
\setlength{\parskip}{0.2 cm}
\title{Notes articles}
\author{Maxime GONTHIER Samuel THIBAULT Loris MARCHAL}

\newcommand{\card}[1]{\ensuremath{\left|{#1}\right|}\xspace}
\newcommand{\live}{\ensuremath{L}\xspace}
\newcommand{\evict}{\ensuremath{\mathcal{V}}\xspace}
\newcommand{\dataset}{\ensuremath{\mathbb{D}}\xspace}
\newcommand{\taskset}{\ensuremath{\mathbb{T}}\xspace}
\newcommand{\packageset}{\ensuremath{\mathbb{P}}\xspace}
\newcommand{\inputs}{\ensuremath{\mathcal{D}}\xspace}
\newcommand{\optpb}{\textsc{Min\-Loads\-For\-Tasks\-Sharing\-Data}\xspace}
\newcommand{\nbloads}{\ensuremath{\mathit{\mathit{\#Loads}}}\xspace}
\newcommand{\MIN}{\ensuremath{\mathit{MIN}}\xspace}
\newcommand{\starpu}{\textsc{StarPU}\xspace}
\newcommand{\nbPU}{\ensuremath{\vert PU \vert}\xspace}

\usepackage{tikz}
\usetikzlibrary{fit, shapes.geometric, patterns}

\makeatletter\tikzset{hatch distance/.store in=\hatchdistance,hatch distance=5pt,hatch thickness/.store in=\hatchthickness,hatch thickness=5pt}\pgfdeclarepatternformonly[\hatchdistance,\hatchthickness]{north east hatch}{\pgfqpoint{-1pt}{-1pt}}{\pgfqpoint{\hatchdistance}{\hatchdistance}}{\pgfpoint{\hatchdistance-1pt}{\hatchdistance-1pt}}{\pgfsetcolor{\tikz@pattern@color}\pgfsetlinewidth{\hatchthickness}\pgfpathmoveto{\pgfqpoint{0pt}{0pt}}\pgfpathlineto{\pgfqpoint{\hatchdistance}{\hatchdistance}}\pgfusepath{stroke}}\makeatother\usetikzlibrary{calc,shadings,patterns,tikzmark}\newcommand\HatchedCell[5][0pt]{\begin{tikzpicture}[overlay,remember picture]\path ($(pic cs:#2)!0.5!(pic cs:#3)$)coordinate(aux1)(pic cs:#4)coordinate(aux2);\fill[#5]($(aux1)+(-0.23*0.075\textwidth,1.9ex)$)rectangle($(aux1 |- aux2)+(0.23*0.075\textwidth,-#1*\baselineskip-.8ex)$);\end{tikzpicture}}

\newcounter{nodemarkers}
\newcommand\circletext[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-\arabic{nodemarkers}-a) at (0,1.5ex) {};%
    #1%
    \tikz[overlay,remember picture]
        \node (marker-\arabic{nodemarkers}-b) at (0,0){};%
    \tikz[overlay,remember picture,inner sep=2pt]
        \node[draw,ellipse,fit=(marker-\arabic{nodemarkers}-a.center) (marker-\arabic{nodemarkers}-b.center)] {};%
    \stepcounter{nodemarkers}%
}

% Pour les checkmark
\newcommand*\colourcheck[1]{%
  \expandafter\newcommand\csname #1check\endcsname{\textcolor{#1}{\ding{52}}}
}
\colourcheck{green}
\newcommand{\ok}[1]{\textcolor{ForestGreen}{OK \greencheck}}
\newcommand{\oktext}[1]{\textcolor{ForestGreen}{OK \greencheck}~\textcolor{ForestGreen}{#1}}

\begin{document}

%~ \tableofcontents
\newpage

\section{What's new since last meeting ?}

	\begin{enumerate}
		\item Diapos
		\item Correction de maximum use single file
		\item Code to have 3 days and keep only the second one for stats
		\item New results with 3 days and keeping only one of them
		\item Début inscription D3
		\item Courbe Stats sur la charge du cluster au cours de l'exec
	\end{enumerate}
	
\section{Questions for next meeting}

	\begin{enumerate}
		\item ACACES
		\item It's now a 100 seconds frame to have similar input files for 2 jobs of the same user. Is it ok ?
		\item Stefanos: "Cache Replacement Based on Reuse-Distance Prediction". Try to predict reuse distance and use this information for eviction. The main idea is that the future is not know but you can still predict it to make decision, just like in our case with tasks and data. Here reuse distance is two consecutive access of the smae cacheline. But can be extended to data for us. Use real information and a prediction with a confidence. As the real information is updated, so is the confidence of the prediction (decreased or increased). Then discussion very specific to caches sizes. To know what to evict: "We look for the cacheline that is going to be accessed farthest in the future by computing its Estimated Time of Access (ETA). The ETA of a line is the time it was last accessed plus its predicted reuse-distance minus the current time. In other words, a cacheline’s ETA is the (predicted) number of accesses that separate the present moment from its next access". In the case they have no prediction they just evict cacheline whose predicted reuse time has passed. Once a cacheline was found the fiursthers in the future, they won't necessarly evict it cause you can find even better sometimes. "The longer a line remains unaccessed the higher the probability that it is useless". We now have two candidates, quantified by exactly the same metric: time measured in accesses. One candidate is the line with the largest ETA (the ETA line), and the other is the line with the largest Decay time (the LRU line). We pick the largest of the two for replacement. IN OUR CASE: We want the workload to be unknown and possibly not regular ? So we would need to estimate the number of time a data will be used to get the next reuse time. Or we could look at the frequency of usage of a data in the past to predict the future. So if a data is used a lot in short interval we can say that the next use is soon. Whereas if it's used only sparsely, we can evict it cause anyway it's not regular. + We can use our buffer information.
		\item Inscription D3
		\item Plénière: Prix inscription et présentation
		\item Change percentage of task with 256 or 1024 files? 
	\end{enumerate}

\section{Todo}
	\subsection{General}
		\begin{enumerate}
			\item Cours pour l'année prochaine
			\item Après avis favorable déposer dossier sur SIGED
			\item Similar results: look if it's exactly the same or it is because the cluster is mainly empty ? Do they take exactly the same decision ? Does easy back fill really change anything or it just reschedule like FCFS ?
			\item Elongation: multiply each submission time by a constant
			\item The cluster is empty most of the time: Test with full workload and a smaller cluster but not 4 nodes and 3 phases as well
			\item Idea algo: 6.2 + penalty for fcfs + easybf or conservative bf
			\item Se ré inscrire à l'ENS avant le 15 Juin
			\item Refelchir a maximum use en mieux
			\item faire des boxplots
			\item faire option easy bf a la place de shceuler en particulier
			\item surprr code inutile
			\item Voir thèses de Herman
			\item Talk to Hans Karlsson
			\item Talk to David Black-Schaffer
			\item Lire articles Emanuel Rubensson \url{https://webmail.ens-lyon.fr/?_task=mail&_caps=pdf%3D1%2Cflash%3D0%2Ctif%3D0&_uid=4630&_mbox=INBOX&_action=show}
			\item Compare algo with different workloads. Use queue time of each job compared to a baseline. Compare queue time of each job between 2 heuristics by saying who won on each queue time.
			\item Ajouter algos qui reschedule de temps en temps
			\item Code to compare ourselves, HEFT that would be FCFS that take into consideration transfer time for the earliest available cores
			\item Use same X scale for distributions of queue times
			\item Use same X scale workloads stats
			\item Use same X scale for some gantt charts when I want to compare them
			\item Code algo 2
			\item vidéo IPDPS avant le 15 mai
			\item TODO du code: backfill, available node list qui contient les cores available aussi
			\item contrainte de la localié sur la taille de la données, contrainte sur les coeurs, contrainte sur les partage de données
			\item stratégie qui essaye d'utiliser moins les gros noeud pour les garder pour les gros jobs ?
			\item Lors d'une exec imprimer sur le terminal et dans le fichier de résultats les stats sur le workload et le cluster
			\item Comparer algo qui reschedule tout et algo qui schedule que quand un nouveau core est disponible et ne schedule que 1 seul job a la fois par cores.
			\item lire article bf : Utilization, Predictability, Workloads
			\item Faire plusieurs test et mettre une barre d'erreur
			\item Afficher temps de transferts sur les Gantt charts
		\end{enumerate}
	\subsection{Batsim}
		\begin{enumerate}
			\item Batsim a pas la granularité au sein d'un noeud
			\item Gérer n nodes
			\item Gérer n jobs
			\item Faire un delay aussi long que la somme du poids des données manquantes
			\item faire la maj des données du node partout, sois Dans le scheduler sois dans fit mais faut le faire!
			\item Gérér à la main les évictions
		\end{enumerate}

\end{document}
