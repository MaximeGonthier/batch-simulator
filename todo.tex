\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{diagbox}
\usepackage{colortbl}
\usepackage{pdfpages}
\usepackage{todonotes}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{xcolor,pifont}
\usepackage{fullpage}
\usepackage{algorithm, algpseudocode}
\usepackage[hidelinks]{hyperref}
\usepackage[english]{babel}
%~ \usepackage[backend=bibtex]{biblatex}
%~ \bibliography{ref_cadre}
\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newtheorem{Problem}{Problem}
\newtheorem{Theorem}{Theorem}
\newtheorem{Lemma}{Lemma}
\newtheorem{Hypothesis}{Hypothesis}
\providecommand{\keywords}[1]{\textbf{\textit{Key-words:}} #1}
\newcommand{\LM}[1]{\textcolor{red}{LM:~{#1}}}
\newcommand{\ST}[1]{\textcolor{orange}{ST:~{#1}}}
\newcommand{\TODO}[1]{\textcolor{olive}{TODO:~{#1}}}
\newcommand{\Q}[1]{\textcolor{blue}{Q:~{#1}}}
\setlength{\parskip}{0.2 cm}
\title{Notes articles}
\author{Maxime GONTHIER Samuel THIBAULT Loris MARCHAL}

\newcommand{\card}[1]{\ensuremath{\left|{#1}\right|}\xspace}
\newcommand{\live}{\ensuremath{L}\xspace}
\newcommand{\evict}{\ensuremath{\mathcal{V}}\xspace}
\newcommand{\dataset}{\ensuremath{\mathbb{D}}\xspace}
\newcommand{\taskset}{\ensuremath{\mathbb{T}}\xspace}
\newcommand{\packageset}{\ensuremath{\mathbb{P}}\xspace}
\newcommand{\inputs}{\ensuremath{\mathcal{D}}\xspace}
\newcommand{\optpb}{\textsc{Min\-Loads\-For\-Tasks\-Sharing\-Data}\xspace}
\newcommand{\nbloads}{\ensuremath{\mathit{\mathit{\#Loads}}}\xspace}
\newcommand{\MIN}{\ensuremath{\mathit{MIN}}\xspace}
\newcommand{\starpu}{\textsc{StarPU}\xspace}
\newcommand{\nbPU}{\ensuremath{\vert PU \vert}\xspace}

\usepackage{tikz}
\usetikzlibrary{fit, shapes.geometric, patterns}

\makeatletter\tikzset{hatch distance/.store in=\hatchdistance,hatch distance=5pt,hatch thickness/.store in=\hatchthickness,hatch thickness=5pt}\pgfdeclarepatternformonly[\hatchdistance,\hatchthickness]{north east hatch}{\pgfqpoint{-1pt}{-1pt}}{\pgfqpoint{\hatchdistance}{\hatchdistance}}{\pgfpoint{\hatchdistance-1pt}{\hatchdistance-1pt}}{\pgfsetcolor{\tikz@pattern@color}\pgfsetlinewidth{\hatchthickness}\pgfpathmoveto{\pgfqpoint{0pt}{0pt}}\pgfpathlineto{\pgfqpoint{\hatchdistance}{\hatchdistance}}\pgfusepath{stroke}}\makeatother\usetikzlibrary{calc,shadings,patterns,tikzmark}\newcommand\HatchedCell[5][0pt]{\begin{tikzpicture}[overlay,remember picture]\path ($(pic cs:#2)!0.5!(pic cs:#3)$)coordinate(aux1)(pic cs:#4)coordinate(aux2);\fill[#5]($(aux1)+(-0.23*0.075\textwidth,1.9ex)$)rectangle($(aux1 |- aux2)+(0.23*0.075\textwidth,-#1*\baselineskip-.8ex)$);\end{tikzpicture}}

\newcounter{nodemarkers}
\newcommand\circletext[1]{%
    \tikz[overlay,remember picture] 
        \node (marker-\arabic{nodemarkers}-a) at (0,1.5ex) {};%
    #1%
    \tikz[overlay,remember picture]
        \node (marker-\arabic{nodemarkers}-b) at (0,0){};%
    \tikz[overlay,remember picture,inner sep=2pt]
        \node[draw,ellipse,fit=(marker-\arabic{nodemarkers}-a.center) (marker-\arabic{nodemarkers}-b.center)] {};%
    \stepcounter{nodemarkers}%
}

% Pour les checkmark
\newcommand*\colourcheck[1]{%
  \expandafter\newcommand\csname #1check\endcsname{\textcolor{#1}{\ding{52}}}
}
\colourcheck{green}
\newcommand{\ok}[1]{\textcolor{ForestGreen}{OK \greencheck}}
\newcommand{\oktext}[1]{\textcolor{ForestGreen}{OK \greencheck}~\textcolor{ForestGreen}{#1}}

\begin{document}
\newpage

%~ /data-aware-batch-scheduling/MBSS$ oarsub -p orion -l core=2,walltime=08:00:00 -r '2022-06-14 19:00:00' "bash Stats_single_workload.sh inputs/workloads/converted/test-11 inputs/clusters/rackham_450_128_32_256_4_1024.txt Fcfs 0"

\section{Informations for the article}
	\begin{enumerate}
		\item HEFT is like fcfs with a score x1 x0 x0 x0
		\item Use same X scale for some gantt charts when I want to compare them: to do that add a job of duration 0 at the maxtime of the heuristic you are showing
		\item Faire plusieurs test et mettre une barre d'erreur (ce qui varie c'est la taille des fichiers d'entrées lors de la génération du workload). For this I did Generate\_workload\_from\_rackham\_for\_variance.sh to generate different workloads (10 is enough or I go up to 30 ? Might take a while if I do 30 times the same test. Or maybe just once to show the varaince is small ?) and then I try them all and show the variance.
		\item Use same X scale for workloads stats when I want to compare them
		\item cluster usage in real: https://www.uppmax.uu.se/resources/system-usage/rackham/
		\item About files in the simulation: %\url{https://webmail.ens-lyon.fr/?_task=mail&_caps=pdf%3D1%2Cflash%3D0%2Ctif%3D0&_uid=5368&_mbox=INBOX&_action=show}
	 \end{enumerate}

\section{What's new since last meeting ?}

	\begin{enumerate}
		% Pour elisabeth et carl
		\item Re-writing of area filling
		\item More heatmaps fcfs with a score and all multipliers combination heatmaps
		\item Code area filling ratio and area filling omniscient
		\item pseudo code area filling with different filling of allocated area (It's: Allocated Area[choosen size][x] gets Allocated Area[choosen size][x] + Area(Ji) with Area(Ji) = cores*walltime. But I would prefer to do: cores*(delay+transfer time))
		\item code area filling with ratio and allocated area
		\item code easybf fcfs only
		\item are filling omnisicnet comme je fais en ce moment. Si ca marche pas essayer avec le graduellement
		\item dans area filling: A la place de immedialy est ce que ca finir a plus tot sur le noeud de taille x + 1 et comparer aussi avec x + 2 ... x + n.
		\item Size constraint: sorting by size is bad if normal cluster
		\item ignore dt for constraint == 2
		\item revoir area filling tart dans le main en fct de planned or ratio et des nouveau noms de fichiers et retester avec les 2 cluster différents.
		\item plot with nb of upgraded jobs
		\item plot avec backfill. Ameliore fcfs mais fcfs score est meilleur sans. La diff e transfert est grande entre fcfs score et fcfs score bf
		\item Why are filling so bad ? Even in omniscient ? I corrected a bit but it's still worse. Also there is a difference between true allocated area and the one I compute in the schedule (because the scheduele change and I only update allocated area when a job start. Else I have a temp one just for the current schedule).
		\item Try in area filling to reduce allocated area by the diff between walltime and real delay if the job finished before it's walltime
		\item Comment one paper of vincenc
		\item Mail au gars de data locality sur numa: Jannis Klinkenberg
		\item dossier inscription administrative
		\item attestation sur siged de acaces et IPDPS
		\item plot the number of jobs where the queue time is superior to 25000 for example
		\item tirer quelques conclusions dans le document principal
		\item plot 2 contraintes ensembles
		\item code pour tracer terminaison des jobs -2 sur courbes usage du cluster: mais toujours pas full. Je devrais prendre bcp plus loin dans le futur ?
		\item tester en faisant varier le multiplicateur de fcfs score area filling: je n'observe pas d'améliorations
		\item Afficher temps de transferts sur les Gantt charts
		
		% Reu du 29/08
		\item Pour le workload: ignorer jobs cancelled. Ne pas ignorer job failed ou timeout. Si jobs multi node les diviser. Ajout d'un overhead de 2*1min aux jobs et de 1*2min aux failed. Data sur tous les jobs.
		\item stats sur workload can be plotted
		\item cluster usage is good now
		\item temporalité des gros jobs en terme de submit time
		\item looking at further jobs for workload but not adding them in my schedule if after day2 (14 jours entier et couper pour voir si on a vraiment tout)
		\item ré ecriture des algos fcfs score + backfill big nodes or + area filling
		\item new plots size constraint only
		\item code backfill 95th percentile: trop de complexité car je regarde tout les noeuds

		% Reu du 06/09
		\item voir fonctionnement area filling ratio en détail: penser a update allocated area dans start et end jobs pour les nouveaux algo area filing
		\item Je prendres une semaine plus tôt pour recup les planned and ratio area en cas non omniscient
		\item Je prends 1 mois entier dans le passé pour ratio area
		\item Ré écriture strat backfill 3
		\item code backfill strat 2 et vérifié
		\item code backfill strat 1 corrigé et vérifié
		\item code area filling strat 1 vérifié
		\item code area filling strat 2 et 2bis et vérifié
		\item new plot size constraint pour non omniscient: not shown but we are also better in total flow and total queue time
		\item code backfill start 3 et vérifié
		\item plot size and data constraint. certains algo pas montré car trop long a faire tourner. Le pb de fcfs avec un score est que dans certains cas les multiplicateurs anulle totalement la possiblité d'upgrade des jobs! Ils ne sont pas constant avec les different workloads. Le score l'emporte sur l'upgrade.
		
		% Reu FGCS
		\item il me manque credit to authors signé donc c'est un doublon de contributions mais j'ai upload
		\item Editables files ne fonctionne pas et ils me proposent de soumettre du word.

		% Uppsala
		\item Jan 21: 15295 jobs: 617333/14395675 (4.2\%) tie break (avant le evicted file du coup). Donc faut-il l'utilise comme tiebreak ?
		\item L'ajout de données persistente pose le pb de l'eviction. Je vais faire un LRU qui evince la donnée qui a été fini d'utilisé il y a le + longmemsp (j'aurais aussi pu faire celle qui a commencé le + longemps)
		\item code data peristence avec LRU pour l'eviction et tests
		\item code bf commun en différentes versions. Trop complexe et pas encore retesté
		\item Réduire complexité en ne reschedulant pas tout quand on a juste un nouveau job.
		\item Compter le nb de fois que la persistence est exploité: pour Janvier 17: 14 fois avec FCFS et 20 fois avec SCORE. pour Janvier 21: 8 fois avec FCFS et 29 fois avec SCORE. Avec conservativ bf et 17 et fcfs: avec easy bf et 17 et fcfs: 8
		\item test easy bf et conservative bf avec limite  2 * 486 pour le nombre de cors rescheduled.
		\item test cluster 2 fois plus petit en cours. Rien n'indique que ca correspond.
		\item visu cluster usgae avec job schedule dans la queue
		
		% Depuis la reu de mardi 8/11
		\item Code: coder fcfs score conservative backfill qui ne backfill pas du tout si le job ne peux pas reutiliser une donnée. J'ai pu tester en entier pour que ce soit réaliste
		\item conservative locality pour les algos score j'ai ajouté comme condition sur le backfill: if(time\_to\_load\_file == 0 || time\_to\_reload\_evicted\_files == 0 || is\_being\_loaded == true): ne sert pas en réalité car la donnée sera évincé de toute facon si il y a un trou. Du coup ce que je fais c'est que je cherche juste si un trou me permet de reutiliser la donné. si oui je vais dessus sinon je me backfill sur le premier trou qui viens.
		\item Code: reduire complexité fcfs score conservatif, si j'ai tout recouvert, je scheule pas mais je regarde juste si il rentre dans le trou ou pas.
		\item regarder pic job queu mars 15 16 workload: plein de jobs de taille 4 - 20 mais bcp similaires c'est ca le truc
		\item score crash avec les longst test masi avant c'était pas le cas: diviser en 2
		\item verif perf conservative bf avec eft-score mix (anormalement haut): corrigé

		% Pour mercredi
		\item compter le nb de reutilisation des données (hors persistence)
		\item Figure cluster usage: nb of nodes * 20 et 1 seul axe y. La courbe used nodes by evaluated jobs ne tombe à 0 que très loin car moi j'arrête de regarder dès que j'ai commencé tout les jobs évalués
		\item Début de rédaction de l'article
	\end{enumerate}
	
\section{Questions for next meeting}
	\begin{enumerate}
		\item on est bon sur des cas mais pas tous,  ya des cas vraiment cata pour score et tout le monde est pareil a par lui?. Ca tue un peu les moyenne de tous les workloads.
		\item Quel nom pour les courbes de cluster usage ?
		\item Quand j'ai plusieurs jours d'affilé ou un seul je compte double le ircentage d'amélioration ?
	\end{enumerate}
	
\section{Todo}
	\subsection{General}
		\begin{enumerate}
			\item mail joachim correction
			\item Finir corriger algo
			\item Répondre a Bora hMETIS
			\item Imprimer poster demander à Denis
		\end{enumerate}
	\subsection{FGCS}
		\begin{enumerate}
			\item
		\end{enumerate}
	\subsection{Uppsala}
		\begin{enumerate}
%~ OAR_JOB_ID=1404284 pour mai score save
			\item plot ou comparer nombre de reutilisations de données
			\item voir comment modifier valeur x avec matplotlib pour afficher les heures plutots
			\item recup template ccgrid
			\item maj algo et ecrire pseudocode EASY et CONSERVATIVE BF, comment ca se code d'habitude et comment moi je l'ai codé
			\item verif perf eft score mix car sur cluster occupé ca devrait être comme score. ptet le cluster est pas 100\% utilisé du coup.
			\item test cluster usage avec d'autres algo (utile pour ci dessus peut etre ?)
			\item test + de workload et plot les \% de différences
			\item Abstract le 25 Novembre - Soumission le 2 Décembre
			\item Fig cluster usage: couper un peu a gauche et prendre un peu a droite pour ne montrer quele milieu dans un cas a part special pour montrer + courbe avec cores used workload 1 seuleemnt qui devrais tomber vers la fin + faire demarrer courbe rouge (cores in queue workload 1) que au debut sdu temps d'evaluation et la couper à la fin quand ca vaut 0 si on plot un peu apres (donc avant quanad c'est 0 pas la plot). De même pour cores used evaluated jobs qu'on veut pas voir à 0 avant et apres son utilisation. Tronquer en bloc de exactement 24h ou 12h ou autre. Changer la légende en heures du jour 
			
			
			\item test mai avec conservative bf et comparer avec résultats de easy bf sur la même période
			\item voir ce qui est utilisé sur slurm et oar dans des articles et en demandant directement sur mattermost
			\item contacter gaupy si il connait des survey: att réponse
			
			\item score crash avec conservative backfill car c'est trop long je dois réduire du coup
		
			\item use a simple backfilling strategy to be fair with fcfs et utiliser la même pour tous. Le premier est bien plus conservateur que le second qui peut delay un job a cause d'un walltime trop grand
			\item smooth transtion: probability of needing all nodes ? Try math functions ? tester si ca matvch le nb of nodes en testant d'autres tailles de clusters ?
			\item Garder une donnée si elle rentre en memoire malgré un autre job qui tourne ou commence. Sinon l'enlever. ca appote un problème d'eviction. Du coup j'evince en LRU. La pb que je fias une data dans score or mtn j'ai plus le nb task using it
		
			\item checker les intrvals avec et sans bf voir comment ca marche et si ca marceh bien
			\item tester heft + conservative bf
			\item je backfill si y a 0 eviction sur la node ou si je re utilise le fichier ou si pour ceux que j'ai placé, ils n'utilisent pas ce que je vais évincer.
			\item ajouter conservative bf et conservative bf tres conservateur sur la localité et voir les résultats.
				\item Pas perturber les jobs suivants: si je reutilise le fichier, ou si le noeud n'a pas de fichiers, ou les jobs suivant n'ont pas des fichiers qui sont sur la node.
			\item Compter le nombre de jobs backfilled.
			\item tester sur d'autres workloads
			\item tester avec des clusters plus petits pour voir si le multiplicateur change quelquechose
			\item attention dans fcfs score with conservative bf les intervals sont peut etre faux dans le cas backfill == true et found == true
			\item pour ajouter conservative bf aux autres: attention il faut enlever la boucle sur nb non available et l'utiliser que si c'est t qui est pris. Sinon on compte pas. Il faut donc faire:
			%~ if (j->start_time == t)
			%~ {
				%~ nb_non_available_cores += 1;
			%~ }

			\item Strat1: multiplicateur graduel avec le nb de noeuds occupées
			\item Regarder si on gagne en stretch que sur des jobs très cours ou non. Ca peut etre le cas quand le flow est equivalent mais les mean stretch différents
			\item busy cluster threshold à 100 ? Mis à 100
			\item Strat2: Calculer le flow total sur le set de job qu'il faut schedule. En fnction du resultat choisir sois HEFt sois FCFS score sois LOCALITY
 			
			\item test Fcfs\_with\_a\_score\_mixed\_strategy\_x mais avec different cluster usage
			\item code et test mixed strategy mais avec le eat pour les petits jobs (et avec un multiplicateur qui vaut ???), sinon locality only.
			\item mail recap uppsala (quand calculer le busy ? Quel threshold ? Quel multiplier).
			\item coder verif de busy cluster
			\item Coder algo mix
			\item ecrire heuristique sois heft (x1 x0 x0 x0), sois localité (avec les 2 trucs de localité+comm first et en 2eme critaere le EAT) dans le cas 95 ou 90\%. Et tester sur d'autres workloads.
			\item tester multiplicateur pour area factor
			\item ajouter bf a tous et retester ? J'ai deja quelques courbes et algo codé avec la dessus.
			\item corriger histogrammes stats workloads
			\item tester avec data sur jobs de plus de 5 cores seulement
			\item regarder qui sont les jobs delaier de plus de 25000
			\item test autres workloads pour les 2 contraintes
			\item mettre a jour planned area pour fcfs score area filling quand j'upgrade des jobs ?
			\item generation de workload : aller chercher loin puis cut le fichier plus tôt pour pas avoir trop de jobs non plus ?
			\item Ne pas oublier que j'ai les courbes VS sur flow stretch et queue times aussi que je peux tracer						
		\end{enumerate}
\end{document}
