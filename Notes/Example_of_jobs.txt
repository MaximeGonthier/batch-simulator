2021-11-04 23:51:20 jobstate=COMPLETED jobid=22838152 username=srimag account=snic2021-22-167 start=1636066245 end=1636066280 submit=1636063769 nodes=r72 procs=6 batch=yes jobname=nf-NFCORE_RNASEQ_RNASEQ_SUBREAD_FEATURECOUNTS_(MG_M_RT_rep1) partition=core limit=08:00:00

2021-11-04 23:51:20 jobstate=COMPLETED jobid=22837935 username=srimag account=snic2021-22-167 start=1636066245 end=1636066280 submit=1636063399 nodes=r295 procs=6 batch=yes jobname=nf-NFCORE_RNASEQ_RNASEQ_RSEQC_RSEQC_BAMSTAT_(MG_M_RT_rep3) partition=core limit=08:00:00

2021-11-04 23:51:23 jobstate=COMPLETED jobid=22838258 username=cnluzon account=snic2020-15-9 start=1636066245 end=1636066283 submit=1636064124 nodes=r316 procs=8 batch=yes jobname=deeptools_fingerprint_1273 partition=core limit=18:00:00

2021-11-04 23:51:26 jobstate=COMPLETED jobid=22837181 username=louel account=snic2020-15-61 start=1636064925 end=1636066286 submit=1636061885 nodes=r267 procs=6 batch=yes jobname=nf-MACS2_(K4me3-AZA_R3_vs_input-AZA_R3) partition=core limit=08:00:00

2021-11-04 23:51:28 jobstate=COMPLETED jobid=22837808 username=srimag account=snic2021-22-167 start=1636065915 end=1636066288 submit=1636062979 nodes=r194 procs=6 batch=yes jobname=nf-NFCORE_RNASEQ_RNASEQ_BEDTOOLS_GENOMECOV_(MG_M_RT_rep2) partition=core limit=08:00:00

2021-11-04 23:51:29 jobstate=COMPLETED jobid=22839619 username=madeline account=p2018002 start=1636066245 end=1636066289 submit=1636065930 nodes=r382 procs=1 batch=yes jobname=snakejob.af_counts.3304.sh partition=core limit=1-00:00:00

2021-11-04 23:51:37 jobstate=COMPLETED jobid=22837749 username=louel account=snic2020-15-61 start=1636065585 end=1636066297 submit=1636062750 nodes=r350 procs=6 batch=yes jobname=nf-BIGWIG_(K4me3-COMBO_R2) partition=core limit=08:00:00

2021-11-04 23:51:38 jobstate=COMPLETED jobid=22837869 username=srimag account=snic2021-22-167 start=1636066245 end=1636066298 submit=1636063284 nodes=r47 procs=6 batch=yes jobname=nf-NFCORE_RNASEQ_RNASEQ_RSEQC_RSEQC_INNERDISTANCE_(MG_M_RT_rep3) partition=core limit=08:00:00

2021-11-04 23:51:39 jobstate=COMPLETED jobid=22837873 username=srimag account=snic2021-22-167 start=1636066245 end=1636066299 submit=1636063289 nodes=r58 procs=6 batch=yes jobname=nf-NFCORE_RNASEQ_RNASEQ_RSEQC_RSEQC_JUNCTIONSATURATION_(MG_M_RT_rep3) partition=core limit=08:00:00

2021-11-04 23:51:43 jobstate=COMPLETED jobid=22837899 username=srimag account=snic2021-22-167 start=1636066245 end=1636066303 submit=1636063319 nodes=r173 procs=6 batch=yes jobname=nf-NFCORE_RNASEQ_RNASEQ_STRINGTIE_(MG_M_RT_rep3) partition=core limit=08:00:00

2021-11-04 23:51:45 jobstate=COMPLETED jobid=22831033 username=maxil account=p2018003 start=1636061959 end=1636066304 submit=1636019669 nodes=r461 procs=2 batch=yes jobname=HC_HGDP00769_Japanese.13 partition=core limit=3-00:00:00

2021-11-04 23:51:51 jobstate=COMPLETED jobid=22839641 username=madeline account=p2018002 start=1636066245 end=1636066311 submit=1636065958 nodes=r241 procs=1 batch=yes jobname=snakejob.af_counts.1691.sh partition=core limit=1-00:00:00
----------------------------------------------------------------

One tool that has appeared many times is Kraken2 ( https://github.com/DerrickWood/kraken2/tree/master/src ). It can be used with reference DBs of widely different size, from 5 GB to 400 GB. It mmaps that reference file. About a year ago (around April 14 2021), the user name juliette was running 40 or so jobs, accessing the file /sw/data/Kraken2_data/latest_nt/hash.k2d. It was smaller then, around 200 GB. It’s currently 360 GB. A specific job ID from that period was 19414225.

A specific set of runs causing trouble in our file system due to the resulting small IO requests to central storage were around September 29 2021, from a user called micdon – all jobs from him with job ids starting in 223 and 224 (22[3]….. as a regexp on the ID string), 119 of them.

From September last year, we also had trouble with a tool called hal2maf. A specific set of runs causing trouble in our file system due to the resulting small IO requests to central storage were around September 29 2021, from a user called micdon – all jobs from him with job ids starting in 223 and 224 (22[3]….. as a regexp on the ID string), 119 of them. The file itself is /proj/uppstore2017228/KLT.04.200M/200m_MD/data/new_250_MAMMALS_v2_20201120/HAL/241-mammalian-2020v2.hal, 800GB (!) in size. However, each job was only supposed to access a subregion, and I’m not sure myself to what extent different runs actually accessed the same part of the file. In this sense, the Kraken jobs are a better representative for what we’re looking for.
----------------------------------------------------------------

module load uppmax
squeue
sacct --user=<username>

[maxim@rackham2 ~]$ jobstats -p -r 25756958 or finishedjobinfo -j 25757038 do I have the rights ?
*** snic2021-5-350 is not one of your projects (jobid 25756958)
*** 1 total jobs
*** 1 jobs running, 0 jobs not running
[maxim@rackham2 ~]$ 

look at the accounting history in files named e.g. /sw/share/slurm/rackham/accounting/2021-04-13, and find out job ids for the jobs involved ?
How do you get the files used ?

Get job after certain date of a certain user
sacct -S start-date -u user-name

[maxim@rackham2 ~]$ perl jobstats_maxime -p 25821517
Running '/sw/uppmax/bin/finishedjobinfo -M rackham -j 25821517' for more information, please be patient...
*** Jobid 25821517 not found
*** 1 total jobs
*** 0 jobs run, 1 jobs not run
What am I doing wrong ?
