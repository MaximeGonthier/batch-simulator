Workloads: inputs/workloads/converted/test-11
Cluster: inputs/clusters/rackham_4nodes.txt
Scheduler: Mixed_strategy_if_EAT_is_t
No constraint on sizes (0).
Id: 0 Memory: 128 Bandwidth: 0.100000 Available cores: 20
Id: 1 Memory: 128 Bandwidth: 0.100000 Available cores: 20
Id: 2 Memory: 256 Bandwidth: 0.100000 Available cores: 20
Id: 3 Memory: 1024 Bandwidth: 0.100000 Available cores: 20
Read workload done.
here
No jobs of category 0. First subtime day 0 is set to 0.

Scheduled job list after scheduling -2 jobs from history. Must be full.
After scheduling jobs of workload -2, the number of jobs to schedule at t = 0 is 0.
Start jobs before day 0 done.

Schedule job list after starting - 2. Must be less full.
busy_cluster_threshold is 100.
Start simulation.
We have new jobs at time 0.
New job 1.
New job 2.
New job 3.
New job 4.
New job 5.
New job 6.
New job 7.
New job 8.
New job 9.
New job 10.
New job 11.
New job 12.
Reschedule.
Mix if EAT is t
There are 80/80 available cores.

Need to schedule job 1 using file 1. T = 0
EAT == t.
HEFT SINGLE JOB
Intervals at time 0 are:
Node 0:
Node 1:
Node 2:
Node 3:
On node 0?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 1 is 1280 with node 0.
On node 1?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 1 is 1280 with node 1.
On node 2?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 1 is 1280 with node 2.
On node 3?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 1 is 1280 with node 3.
Need to create a data and intervals for the node 0 data 1.
Job 1 using file 1 category 0 workload 1 will be computed on node 0 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19 start at time 0 and is predicted to finish at time 3600.
There are 60/80 available cores.

Need to schedule job 2 using file 1. T = 0
EAT == t.
HEFT SINGLE JOB
Intervals at time 0 are:
Node 0: 1 ( 0 1280 3600 )
Node 1:
Node 2:
Node 3:
On node 0?
EAT is: 3600.
Data 1 is on node 0.
Interval not empty, but is it on the node at time 3600 ?
Checking 0 / 1280 / 3600.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 2 is 3600 with node 0.
On node 1?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 2 is 1280 with node 1.
On node 2?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 2 is 1280 with node 2.
On node 3?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 2 is 1280 with node 3.
Need to create a data and intervals for the node 1 data 1.
Job 2 using file 1 category 0 workload 1 will be computed on node 1 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19 start at time 0 and is predicted to finish at time 3600.
There are 40/80 available cores.

Need to schedule job 3 using file 1. T = 0
EAT == t.
HEFT SINGLE JOB
Intervals at time 0 are:
Node 0: 1 ( 0 1280 3600 )
Node 1: 1 ( 0 1280 3600 )
Node 2:
Node 3:
On node 0?
EAT is: 3600.
Data 1 is on node 0.
Interval not empty, but is it on the node at time 3600 ?
Checking 0 / 1280 / 3600.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 3 is 3600 with node 0.
On node 1?
EAT is: 3600.
On node 2?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 3 is 1280 with node 2.
On node 3?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 3 is 1280 with node 3.
Need to create a data and intervals for the node 2 data 1.
Job 3 using file 1 category 0 workload 1 will be computed on node 2 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19 start at time 0 and is predicted to finish at time 3600.
There are 20/80 available cores.

Need to schedule job 4 using file 1. T = 0
EAT == t.
HEFT SINGLE JOB
Intervals at time 0 are:
Node 0: 1 ( 0 1280 3600 )
Node 1: 1 ( 0 1280 3600 )
Node 2: 1 ( 0 1280 3600 )
Node 3:
On node 0?
EAT is: 3600.
Data 1 is on node 0.
Interval not empty, but is it on the node at time 3600 ?
Checking 0 / 1280 / 3600.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 4 is 3600 with node 0.
On node 1?
EAT is: 3600.
On node 2?
EAT is: 3600.
On node 3?
EAT is: 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 4 is 1280 with node 3.
Need to create a data and intervals for the node 3 data 1.
Job 4 using file 1 category 0 workload 1 will be computed on node 3 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19 start at time 0 and is predicted to finish at time 3600.
No more available cores.
End of reschedule.
Start of start_jobs at time 0.
Adding data 1 on node 0 at time 0.
For job 1 (delay = 1000): 1280 transfer time and 0 waiting for a load time. Overhead is 1280
==> Job 1 20 cores start at time 0 on node 0 and will end at time 2280 before walltime: 1 transfer time is 1280 data was 1.
Adding data 1 on node 1 at time 0.
For job 2 (delay = 1000): 1280 transfer time and 0 waiting for a load time. Overhead is 1280
==> Job 2 20 cores start at time 0 on node 1 and will end at time 2280 before walltime: 1 transfer time is 1280 data was 1.
Adding data 1 on node 2 at time 0.
For job 3 (delay = 1000): 1280 transfer time and 0 waiting for a load time. Overhead is 1280
==> Job 3 20 cores start at time 0 on node 2 and will end at time 2280 before walltime: 1 transfer time is 1280 data was 1.
Adding data 1 on node 3 at time 0.
For job 4 (delay = 1000): 1280 transfer time and 0 waiting for a load time. Overhead is 1280
==> Job 4 20 cores start at time 0 on node 3 and will end at time 2280 before walltime: 1 transfer time is 1280 data was 1.
We have new jobs at time 1000.
New job 13.
Reschedule.
Mix if EAT is t
No more available cores.
End of reschedule.
We have new jobs at time 1020.
New job 14.
Reschedule.
Mix if EAT is t
No more available cores.
End of reschedule.
We have new jobs at time 1080.
New job 15.
Reschedule.
Mix if EAT is t
No more available cores.
End of reschedule.
We have new jobs at time 1100.
New job 16.
Reschedule.
Mix if EAT is t
No more available cores.
End of reschedule.
We have new jobs at time 1150.
New job 17.
Reschedule.
Mix if EAT is t
No more available cores.
End of reschedule.
Start of end_jobs at time 2280.
==> Job 1 20 cores finished at time 2280 on node 0.
==> Job 2 20 cores finished at time 2280 on node 1.
==> Job 3 20 cores finished at time 2280 on node 2.
==> Job 4 20 cores finished at time 2280 on node 3.
Reschedule.
Mix if EAT is t
There are 80/80 available cores.

Need to schedule job 5 using file 1. T = 2280
EAT == t.
HEFT SINGLE JOB
Intervals at time 2280 are:
Node 0: 1 ( 2280 2280 2280 )
Node 1: 1 ( 2280 2280 2280 )
Node 2: 1 ( 2280 2280 2280 )
Node 3: 1 ( 2280 2280 2280 )
On node 0?
EAT is: 2280.
Data 1 is on node 0.
Interval not empty, but is it on the node at time 2280 ?
Checking 2280 / 2280 / 2280.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 5 is 2280 with node 0.
On node 1?
EAT is: 2280.
On node 2?
EAT is: 2280.
On node 3?
EAT is: 2280.
Job 5 using file 1 category 0 workload 1 will be computed on node 0 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19 start at time 2280 and is predicted to finish at time 5880.
There are 60/80 available cores.

Need to schedule job 6 using file 2. T = 2280
EAT == t.
HEFT SINGLE JOB
Intervals at time 2280 are:
Node 0: 1 ( 2280 2280 2280 2280 2280 5880 )
Node 1: 1 ( 2280 2280 2280 )
Node 2: 1 ( 2280 2280 2280 )
Node 3: 1 ( 2280 2280 2280 )
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 6 is 6200 with node 0.
On node 1?
EAT is: 2280.
Data 1 is on node 1.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 6 is 2600 with node 1.
On node 2?
EAT is: 2280.
Data 1 is on node 2.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 6 is 2600 with node 2.
On node 3?
EAT is: 2280.
Data 1 is on node 3.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 6 is 2600 with node 3.
Need to create a data and intervals for the node 1 data 2.
Job 6 using file 2 category 0 workload 1 will be computed on node 1 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14 start at time 2280 and is predicted to finish at time 5380.
There are 45/80 available cores.

Need to schedule job 7 using file 2. T = 2280
EAT == t.
HEFT SINGLE JOB
Intervals at time 2280 are:
Node 0: 1 ( 2280 2280 2280 2280 2280 5880 )
Node 1: 1 ( 2280 2280 2280 ) 2 ( 2280 2600 5380 )
Node 2: 1 ( 2280 2280 2280 )
Node 3: 1 ( 2280 2280 2280 )
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 7 is 7160 with node 0.
On node 1?
EAT is: 5380.
Data 1 is on node 1.
Data 2 is on node 1.
Interval not empty, but is it on the node at time 5380 ?
Checking 2280 / 2600 / 5380.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 7 is 5380 with node 1.
On node 2?
EAT is: 2280.
Data 1 is on node 2.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 7 is 3560 with node 2.
On node 3?
EAT is: 2280.
Data 1 is on node 3.
Time to load file: 1280.000000. Is being loaded? 0.
Score for job 7 is 3560 with node 3.
Need to create a data and intervals for the node 2 data 2.
Job 7 using file 2 category 0 workload 1 will be computed on node 2 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14 start at time 2280 and is predicted to finish at time 5880.
There are 30/80 available cores.

Need to schedule job 8 using file 2. T = 2280
EAT == t.
HEFT SINGLE JOB
Intervals at time 2280 are:
Node 0: 1 ( 2280 2280 2280 2280 2280 5880 )
Node 1: 1 ( 2280 2280 2280 ) 2 ( 2280 2600 5380 )
Node 2: 1 ( 2280 2280 2280 ) 2 ( 2280 3560 5880 )
Node 3: 1 ( 2280 2280 2280 )
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Time to load file: 640.000000. Is being loaded? 0.
Score for job 8 is 6520 with node 0.
On node 1?
EAT is: 5380.
Data 1 is on node 1.
Data 2 is on node 1.
Interval not empty, but is it on the node at time 5380 ?
Checking 2280 / 2600 / 5380.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 8 is 5380 with node 1.
On node 2?
EAT is: 5880.
On node 3?
EAT is: 2280.
Data 1 is on node 3.
Time to load file: 640.000000. Is being loaded? 0.
Score for job 8 is 2920 with node 3.
Need to create a data and intervals for the node 3 data 2.
Job 8 using file 2 category 0 workload 1 will be computed on node 3 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14 start at time 2280 and is predicted to finish at time 5880.
There are 15/80 available cores.

Need to schedule job 9 using file 2. T = 2280
LOCALITY SINGLE JOB
There are 15/80 available cores.

Need to schedule job 9 using file 2. T = 2280
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Checking tail of the interval of data 1: 5880->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 9 is 3520 (TL 2560.000000 + TLE 960.000000) with node 0.
On node 1?
EAT is: 5380.
Data 1 is on node 1.
Data 2 is on node 1.
Interval not empty, but is it on the node at time 5380 ?
Checking 2280 / 2600 / 5380.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 9 is 960 (TL 0.000000 + TLE 960.000000) with node 1.
On node 2?
EAT is: 5880.
Data 1 is on node 2.
Data 2 is on node 2.
Interval not empty, but is it on the node at time 5880 ?
Checking 2280 / 3560 / 5880.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 9 is 960 (TL 0.000000 + TLE 960.000000) with node 2.
On node 3?
EAT is: 5880.
Data 1 is on node 3.
Data 2 is on node 3.
Interval not empty, but is it on the node at time 5880 ?
Checking 2280 / 2920 / 5880.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 9 is 960 (TL 0.000000 + TLE 960.000000) with node 3.
Job 9 using file 2 category 0 workload 1 will be computed on node 1 core(s) 15,16,17,18,19,0,1,2,3,4,5,6,7,8,9 start at time 5380 and is predicted to finish at time 8980.
There are 10/80 available cores.

Need to schedule job 10 using file 2. T = 2280
LOCALITY SINGLE JOB
There are 10/80 available cores.

Need to schedule job 10 using file 2. T = 2280
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Checking tail of the interval of data 1: 5880->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 10 is 2240 (TL 1280.000000 + TLE 960.000000) with node 0.
On node 1?
EAT is: 8980.
Data 1 is on node 1.
Data 2 is on node 1.
Interval not empty, but is it on the node at time 8980 ?
Checking 2280 / 2600 / 5380.
Checking 5380 / 5380 / 8980.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 10 is 960 (TL 0.000000 + TLE 960.000000) with node 1.
On node 2?
EAT is: 5880.
Data 1 is on node 2.
Data 2 is on node 2.
Interval not empty, but is it on the node at time 5880 ?
Checking 2280 / 3560 / 5880.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 10 is 960 (TL 0.000000 + TLE 960.000000) with node 2.
On node 3?
EAT is: 5880.
Data 1 is on node 3.
Data 2 is on node 3.
Interval not empty, but is it on the node at time 5880 ?
Checking 2280 / 2920 / 5880.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 10 is 960 (TL 0.000000 + TLE 960.000000) with node 3.
Job 10 using file 2 category 0 workload 1 will be computed on node 2 core(s) 15,16,17,18,19,0,1,2,3,4,5,6,7,8,9 start at time 5880 and is predicted to finish at time 9480.
There are 5/80 available cores.

Need to schedule job 11 using file 2. T = 2280
LOCALITY SINGLE JOB
There are 5/80 available cores.

Need to schedule job 11 using file 2. T = 2280
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Checking tail of the interval of data 1: 5880->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 11 is 2240 (TL 1280.000000 + TLE 960.000000) with node 0.
On node 1?
EAT is: 8980.
Data 1 is on node 1.
Data 2 is on node 1.
Interval not empty, but is it on the node at time 8980 ?
Checking 2280 / 2600 / 5380.
Checking 5380 / 5380 / 8980.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 11 is 960 (TL 0.000000 + TLE 960.000000) with node 1.
On node 2?
EAT is: 9480.
Data 1 is on node 2.
Data 2 is on node 2.
Interval not empty, but is it on the node at time 9480 ?
Checking 2280 / 3560 / 5880.
Checking 5880 / 5880 / 9480.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 11 is 960 (TL 0.000000 + TLE 960.000000) with node 2.
On node 3?
EAT is: 5880.
Data 1 is on node 3.
Data 2 is on node 3.
Interval not empty, but is it on the node at time 5880 ?
Checking 2280 / 2920 / 5880.
Checking tail of the interval of data 1: 2280->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 11 is 960 (TL 0.000000 + TLE 960.000000) with node 3.
Job 11 using file 2 category 0 workload 1 will be computed on node 3 core(s) 15,16,17,18,19,0,1,2,3,4,5,6,7,8,9 start at time 5880 and is predicted to finish at time 9480.
No more available cores.
End of reschedule.
Start of start_jobs at time 2280.
Adding data 1 on node 0 at time 2280.
For job 5 (delay = 5000): 0 transfer time and 0 waiting for a load time. Overhead is 0
==> Job 5 20 cores start at time 2280 on node 0 and will end at time 5880 before walltime: 0 transfer time is 0 data was 1.
Adding data 2 on node 1 at time 2280.
For job 6 (delay = 3000): 320 transfer time and 0 waiting for a load time. Overhead is 320
==> Job 6 15 cores start at time 2280 on node 1 and will end at time 5380 before walltime: 0 transfer time is 320 data was 2.
Adding data 2 on node 2 at time 2280.
For job 7 (delay = 3600): 1280 transfer time and 0 waiting for a load time. Overhead is 1280
==> Job 7 15 cores start at time 2280 on node 2 and will end at time 5880 before walltime: 0 transfer time is 1280 data was 2.
Adding data 2 on node 3 at time 2280.
For job 8 (delay = 3000): 640 transfer time and 0 waiting for a load time. Overhead is 640
==> Job 8 15 cores start at time 2280 on node 3 and will end at time 5880 before walltime: 0 transfer time is 640 data was 2.
Start of end_jobs at time 5380.
==> Job 6 15 cores finished at time 5380 on node 1.
Start of start_jobs at time 5380.
Adding data 2 on node 1 at time 5380.
For job 9 (delay = 3600): 0 transfer time and 0 waiting for a load time. Overhead is 0
==> Job 9 15 cores start at time 5380 on node 1 and will end at time 8980 before walltime: 0 transfer time is 0 data was 2.
Reschedule.
Mix if EAT is t
There are 15/80 available cores.

Need to schedule job 10 using file 2. T = 5380
LOCALITY SINGLE JOB
There are 15/80 available cores.

Need to schedule job 10 using file 2. T = 5380
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Checking tail of the interval of data 1: 5880->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 10 is 2240 (TL 1280.000000 + TLE 960.000000) with node 0.
On node 1?
EAT is: 8980.
Data 1 is on node 1.
Data 2 is on node 1.
Interval not empty, but is it on the node at time 8980 ?
Checking 5380 / 5380 / 8980.
Total size of data on node ending before my EAT is: 0.000000 but I return (0.750000*0.000000)/0.100000 = 0.000000.
Time to reload evicted files 0.000000.
Score for job 10 is 0 (TL 0.000000 + TLE 0.000000) with node 1.
On node 2?
EAT is: 5880.
Data 1 is on node 2.
Data 2 is on node 2.
Interval not empty, but is it on the node at time 5880 ?
Checking 5380 / 5380 / 5880.
Total size of data on node ending before my EAT is: 0.000000 but I return (0.750000*0.000000)/0.100000 = 0.000000.
Time to reload evicted files 0.000000.
Score for job 10 is 0 (TL 0.000000 + TLE 0.000000) with node 2.
On node 3?
EAT is: 5880.
Job 10 using file 2 category 0 workload 1 will be computed on node 2 core(s) 15,16,17,18,19,10,11,12,13,14,0,1,2,3,4 start at time 5880 and is predicted to finish at time 9480.
There are 10/80 available cores.

Need to schedule job 11 using file 2. T = 5380
LOCALITY SINGLE JOB
There are 10/80 available cores.

Need to schedule job 11 using file 2. T = 5380
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Checking tail of the interval of data 1: 5880->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 11 is 2240 (TL 1280.000000 + TLE 960.000000) with node 0.
On node 1?
EAT is: 8980.
Data 1 is on node 1.
Data 2 is on node 1.
Interval not empty, but is it on the node at time 8980 ?
Checking 5380 / 5380 / 8980.
Total size of data on node ending before my EAT is: 0.000000 but I return (0.750000*0.000000)/0.100000 = 0.000000.
Time to reload evicted files 0.000000.
Score for job 11 is 0 (TL 0.000000 + TLE 0.000000) with node 1.
On node 2?
EAT is: 9480.
On node 3?
EAT is: 5880.
Data 1 is on node 3.
Data 2 is on node 3.
Interval not empty, but is it on the node at time 5880 ?
Checking 5380 / 5380 / 5880.
Total size of data on node ending before my EAT is: 0.000000 but I return (0.750000*0.000000)/0.100000 = 0.000000.
Time to reload evicted files 0.000000.
Score for job 11 is 0 (TL 0.000000 + TLE 0.000000) with node 3.
Job 11 using file 2 category 0 workload 1 will be computed on node 3 core(s) 15,16,17,18,19,10,11,12,13,14,0,1,2,3,4 start at time 5880 and is predicted to finish at time 9480.
There are 5/80 available cores.

Need to schedule job 12 using file 2. T = 5380
LOCALITY SINGLE JOB
There are 5/80 available cores.

Need to schedule job 12 using file 2. T = 5380
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Checking tail of the interval of data 1: 5880->
Add size 128.000000->
Total size of data on node ending before my EAT is: 128.000000 but I return (0.750000*128.000000)/0.100000 = 960.000000.
Time to reload evicted files 960.000000.
Score for job 12 is 1280 (TL 320.000000 + TLE 960.000000) with node 0.
On node 1?
EAT is: 8980.
Data 1 is on node 1.
Data 2 is on node 1.
Interval not empty, but is it on the node at time 8980 ?
Checking 5380 / 5380 / 8980.
Total size of data on node ending before my EAT is: 0.000000 but I return (0.750000*0.000000)/0.100000 = 0.000000.
Time to reload evicted files 0.000000.
Score for job 12 is 0 (TL 0.000000 + TLE 0.000000) with node 1.
On node 2?
EAT is: 9480.
On node 3?
EAT is: 9480.
Job 12 using file 2 category 0 workload 1 will be computed on node 1 core(s) 10,11,12,13,14,15,16,17,18,19,0,1,2,3,4 start at time 8980 and is predicted to finish at time 11980.
No more available cores.
End of reschedule.
Start of end_jobs at time 5880.
==> Job 5 20 cores finished at time 5880 on node 0.
==> Job 7 15 cores finished at time 5880 on node 2.
==> Job 8 15 cores finished at time 5880 on node 3.
Start of start_jobs at time 5880.
Adding data 2 on node 2 at time 5880.
For job 10 (delay = 3600): 0 transfer time and 0 waiting for a load time. Overhead is 0
==> Job 10 15 cores start at time 5880 on node 2 and will end at time 9480 before walltime: 0 transfer time is 0 data was 2.
Adding data 2 on node 3 at time 5880.
For job 11 (delay = 3600): 0 transfer time and 0 waiting for a load time. Overhead is 0
==> Job 11 15 cores start at time 5880 on node 3 and will end at time 9480 before walltime: 0 transfer time is 0 data was 2.
Reschedule.
Mix if EAT is t
There are 35/80 available cores.

Need to schedule job 12 using file 2. T = 5880
EAT == t.
HEFT SINGLE JOB
Intervals at time 5880 are:
Node 0: 1 ( 5880 5880 5880 )
Node 1: 1 ( ) 2 ( 5880 5880 8980 )
Node 2: 1 ( ) 2 ( 5880 5880 9480 )
Node 3: 1 ( ) 2 ( 5880 5880 9480 )
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 12 is 6200 with node 0.
On node 1?
EAT is: 8980.
On node 2?
EAT is: 9480.
On node 3?
EAT is: 9480.
Need to create a data and intervals for the node 0 data 2.
Job 12 using file 2 category 0 workload 1 will be computed on node 0 core(s) 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14 start at time 5880 and is predicted to finish at time 8880.
There are 20/80 available cores.

Need to schedule job 13 using file 3. T = 5880
EAT == t.
HEFT SINGLE JOB
Intervals at time 5880 are:
Node 0: 1 ( 5880 5880 5880 ) 2 ( 5880 6200 8880 )
Node 1: 1 ( ) 2 ( 5880 5880 8980 )
Node 2: 1 ( ) 2 ( 5880 5880 9480 )
Node 3: 1 ( ) 2 ( 5880 5880 9480 )
On node 0?
EAT is: 5880.
Data 1 is on node 0.
Data 2 is on node 0.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 13 is 6200 with node 0.
On node 1?
EAT is: 5880.
Data 1 is on node 1.
Data 2 is on node 1.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 13 is 6200 with node 1.
On node 2?
EAT is: 5880.
Data 1 is on node 2.
Data 2 is on node 2.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 13 is 6200 with node 2.
On node 3?
EAT is: 5880.
Data 1 is on node 3.
Data 2 is on node 3.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 13 is 6200 with node 3.
Need to create a data and intervals for the node 0 data 3.
Job 13 using file 3 category 0 workload 1 will be computed on node 0 core(s) 15,16,17,18,19 start at time 5880 and is predicted to finish at time 8880.
There are 15/80 available cores.

Need to schedule job 14 using file 3. T = 5880
EAT == t.
HEFT SINGLE JOB
Intervals at time 5880 are:
Node 0: 1 ( 5880 5880 5880 ) 2 ( 5880 6200 8880 ) 3 ( 5880 6200 8880 )
Node 1: 1 ( ) 2 ( 5880 5880 8980 )
Node 2: 1 ( ) 2 ( 5880 5880 9480 )
Node 3: 1 ( ) 2 ( 5880 5880 9480 )
On node 0?
EAT is: 8880.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Interval not empty, but is it on the node at time 8880 ?
Checking 5880 / 6200 / 8880.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 14 is 8880 with node 0.
On node 1?
EAT is: 5880.
Data 1 is on node 1.
Data 2 is on node 1.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 14 is 6200 with node 1.
On node 2?
EAT is: 5880.
Data 1 is on node 2.
Data 2 is on node 2.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 14 is 6200 with node 2.
On node 3?
EAT is: 5880.
Data 1 is on node 3.
Data 2 is on node 3.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 14 is 6200 with node 3.
Need to create a data and intervals for the node 1 data 3.
Job 14 using file 3 category 0 workload 1 will be computed on node 1 core(s) 10,11,12,13,14 start at time 5880 and is predicted to finish at time 8880.
There are 10/80 available cores.

Need to schedule job 15 using file 3. T = 5880
EAT == t.
HEFT SINGLE JOB
Intervals at time 5880 are:
Node 0: 1 ( 5880 5880 5880 ) 2 ( 5880 6200 8880 ) 3 ( 5880 6200 8880 )
Node 1: 1 ( ) 2 ( 5880 5880 8980 ) 3 ( 5880 6200 8880 )
Node 2: 1 ( ) 2 ( 5880 5880 9480 )
Node 3: 1 ( ) 2 ( 5880 5880 9480 )
On node 0?
EAT is: 8880.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Interval not empty, but is it on the node at time 8880 ?
Checking 5880 / 6200 / 8880.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 15 is 8880 with node 0.
On node 1?
EAT is: 8880.
On node 2?
EAT is: 5880.
Data 1 is on node 2.
Data 2 is on node 2.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 15 is 6200 with node 2.
On node 3?
EAT is: 5880.
Data 1 is on node 3.
Data 2 is on node 3.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 15 is 6200 with node 3.
Need to create a data and intervals for the node 2 data 3.
Job 15 using file 3 category 0 workload 1 will be computed on node 2 core(s) 5,6,7,8,9 start at time 5880 and is predicted to finish at time 8880.
There are 5/80 available cores.

Need to schedule job 16 using file 3. T = 5880
EAT == t.
HEFT SINGLE JOB
Intervals at time 5880 are:
Node 0: 1 ( 5880 5880 5880 ) 2 ( 5880 6200 8880 ) 3 ( 5880 6200 8880 )
Node 1: 1 ( ) 2 ( 5880 5880 8980 ) 3 ( 5880 6200 8880 )
Node 2: 1 ( ) 2 ( 5880 5880 9480 ) 3 ( 5880 6200 8880 )
Node 3: 1 ( ) 2 ( 5880 5880 9480 )
On node 0?
EAT is: 8880.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Interval not empty, but is it on the node at time 8880 ?
Checking 5880 / 6200 / 8880.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 16 is 8880 with node 0.
On node 1?
EAT is: 8880.
On node 2?
EAT is: 8880.
On node 3?
EAT is: 5880.
Data 1 is on node 3.
Data 2 is on node 3.
Time to load file: 320.000000. Is being loaded? 0.
Score for job 16 is 6200 with node 3.
Need to create a data and intervals for the node 3 data 3.
Job 16 using file 3 category 0 workload 1 will be computed on node 3 core(s) 5,6,7,8,9 start at time 5880 and is predicted to finish at time 8880.
No more available cores.
End of reschedule.
Start of start_jobs at time 5880.
Adding data 2 on node 0 at time 5880.
For job 12 (delay = 2000): 320 transfer time and 0 waiting for a load time. Overhead is 320
==> Job 12 15 cores start at time 5880 on node 0 and will end at time 8200 before walltime: 1 transfer time is 320 data was 2.
Adding data 3 on node 0 at time 5880.
For job 13 (delay = 2000): 320 transfer time and 0 waiting for a load time. Overhead is 320
==> Job 13 5 cores start at time 5880 on node 0 and will end at time 8200 before walltime: 1 transfer time is 320 data was 3.
Adding data 3 on node 1 at time 5880.
For job 14 (delay = 2000): 320 transfer time and 0 waiting for a load time. Overhead is 320
==> Job 14 5 cores start at time 5880 on node 1 and will end at time 8200 before walltime: 1 transfer time is 320 data was 3.
Adding data 3 on node 2 at time 5880.
For job 15 (delay = 2000): 320 transfer time and 0 waiting for a load time. Overhead is 320
==> Job 15 5 cores start at time 5880 on node 2 and will end at time 8200 before walltime: 1 transfer time is 320 data was 3.
Adding data 3 on node 3 at time 5880.
For job 16 (delay = 2000): 320 transfer time and 0 waiting for a load time. Overhead is 320
==> Job 16 5 cores start at time 5880 on node 3 and will end at time 8200 before walltime: 1 transfer time is 320 data was 3.
We have new jobs at time 8000.
New job 18.
New job 19.
New job 20.
New job 21.
New job 22.
New job 23.
New job 24.
New job 25.
Reschedule.
Mix if EAT is t
No more available cores.
End of reschedule.
Start of end_jobs at time 8200.
==> Job 12 15 cores finished at time 8200 on node 0.
==> Job 13 5 cores finished at time 8200 on node 0.
==> Job 14 5 cores finished at time 8200 on node 1.
==> Job 15 5 cores finished at time 8200 on node 2.
==> Job 16 5 cores finished at time 8200 on node 3.
Reschedule.
Mix if EAT is t
There are 35/80 available cores.

Need to schedule job 17 using file 3. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Interval not empty, but is it on the node at time 8200 ?
Checking 8200 / 8200 / 8200.
Time to load file: 0.000000. Is being loaded? 0.
Score for job 17 is 8200 with node 0.
On node 1?
EAT is: 8200.
On node 2?
EAT is: 8200.
On node 3?
EAT is: 8200.
Job 17 using file 3 category 0 workload 1 will be computed on node 0 core(s) 15,16,17,18,19 start at time 8200 and is predicted to finish at time 11200.
There are 30/80 available cores.

Need to schedule job 18 using file 4. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 8200 8200 11200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 18 is 8264 with node 0.
On node 1?
EAT is: 8200.
Data 1 is on node 1.
Data 2 is on node 1.
Data 3 is on node 1.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 18 is 8264 with node 1.
On node 2?
EAT is: 8200.
Data 1 is on node 2.
Data 2 is on node 2.
Data 3 is on node 2.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 18 is 8264 with node 2.
On node 3?
EAT is: 8200.
Data 1 is on node 3.
Data 2 is on node 3.
Data 3 is on node 3.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 18 is 8264 with node 3.
Need to create a data and intervals for the node 0 data 4.
Job 18 using file 4 category 0 workload 1 will be computed on node 0 core(s) 0 start at time 8200 and is predicted to finish at time 11200.
There are 29/80 available cores.

Need to schedule job 19 using file 4. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 8200 8200 11200 ) 4 ( 8200 8264 11200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Data 4 is on node 0.
Interval not empty, but is it on the node at time 8200 ?
Checking 8200 / 8264 / 11200.
Time to load file: 64.000000. Is being loaded? 1.
Score for job 19 is 8264 with node 0.
On node 1?
EAT is: 8200.
Data 1 is on node 1.
Data 2 is on node 1.
Data 3 is on node 1.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 19 is 8264 with node 1.
On node 2?
EAT is: 8200.
Data 1 is on node 2.
Data 2 is on node 2.
Data 3 is on node 2.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 19 is 8264 with node 2.
On node 3?
EAT is: 8200.
Data 1 is on node 3.
Data 2 is on node 3.
Data 3 is on node 3.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 19 is 8264 with node 3.
Job 19 using file 4 category 0 workload 1 will be computed on node 0 core(s) 1 start at time 8200 and is predicted to finish at time 11200.
There are 28/80 available cores.

Need to schedule job 20 using file 4. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 8200 8200 11200 ) 4 ( 8200 8264 11200 8200 8264 11200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Data 4 is on node 0.
Interval not empty, but is it on the node at time 8200 ?
Checking 8200 / 8264 / 11200.
Time to load file: 64.000000. Is being loaded? 1.
Score for job 20 is 8264 with node 0.
On node 1?
EAT is: 8200.
Data 1 is on node 1.
Data 2 is on node 1.
Data 3 is on node 1.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 20 is 8264 with node 1.
On node 2?
EAT is: 8200.
Data 1 is on node 2.
Data 2 is on node 2.
Data 3 is on node 2.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 20 is 8264 with node 2.
On node 3?
EAT is: 8200.
Data 1 is on node 3.
Data 2 is on node 3.
Data 3 is on node 3.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 20 is 8264 with node 3.
Job 20 using file 4 category 0 workload 1 will be computed on node 0 core(s) 2 start at time 8200 and is predicted to finish at time 11200.
There are 27/80 available cores.

Need to schedule job 21 using file 5. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 8200 8200 11200 ) 4 ( 8200 8264 11200 8200 8264 11200 8200 8264 11200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Data 4 is on node 0.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 21 is 8264 with node 0.
On node 1?
EAT is: 8200.
Data 1 is on node 1.
Data 2 is on node 1.
Data 3 is on node 1.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 21 is 8264 with node 1.
On node 2?
EAT is: 8200.
Data 1 is on node 2.
Data 2 is on node 2.
Data 3 is on node 2.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 21 is 8264 with node 2.
On node 3?
EAT is: 8200.
Data 1 is on node 3.
Data 2 is on node 3.
Data 3 is on node 3.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 21 is 8264 with node 3.
Need to create a data and intervals for the node 0 data 5.
Job 21 using file 5 category 0 workload 1 will be computed on node 0 core(s) 3 start at time 8200 and is predicted to finish at time 11200.
There are 26/80 available cores.

Need to schedule job 22 using file 5. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 8200 8200 11200 ) 4 ( 8200 8264 11200 8200 8264 11200 8200 8264 11200 ) 5 ( 8200 8264 11200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Data 4 is on node 0.
Data 5 is on node 0.
Interval not empty, but is it on the node at time 8200 ?
Checking 8200 / 8264 / 11200.
Time to load file: 64.000000. Is being loaded? 1.
Score for job 22 is 8264 with node 0.
On node 1?
EAT is: 8200.
Data 1 is on node 1.
Data 2 is on node 1.
Data 3 is on node 1.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 22 is 8264 with node 1.
On node 2?
EAT is: 8200.
Data 1 is on node 2.
Data 2 is on node 2.
Data 3 is on node 2.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 22 is 8264 with node 2.
On node 3?
EAT is: 8200.
Data 1 is on node 3.
Data 2 is on node 3.
Data 3 is on node 3.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 22 is 8264 with node 3.
Job 22 using file 5 category 0 workload 1 will be computed on node 0 core(s) 4 start at time 8200 and is predicted to finish at time 11200.
There are 25/80 available cores.

Need to schedule job 23 using file 5. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 8200 8200 11200 ) 4 ( 8200 8264 11200 8200 8264 11200 8200 8264 11200 ) 5 ( 8200 8264 11200 8200 8264 11200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Data 4 is on node 0.
Data 5 is on node 0.
Interval not empty, but is it on the node at time 8200 ?
Checking 8200 / 8264 / 11200.
Time to load file: 64.000000. Is being loaded? 1.
Score for job 23 is 8264 with node 0.
On node 1?
EAT is: 8200.
Data 1 is on node 1.
Data 2 is on node 1.
Data 3 is on node 1.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 23 is 8264 with node 1.
On node 2?
EAT is: 8200.
Data 1 is on node 2.
Data 2 is on node 2.
Data 3 is on node 2.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 23 is 8264 with node 2.
On node 3?
EAT is: 8200.
Data 1 is on node 3.
Data 2 is on node 3.
Data 3 is on node 3.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 23 is 8264 with node 3.
Job 23 using file 5 category 0 workload 1 will be computed on node 0 core(s) 5 start at time 8200 and is predicted to finish at time 11200.
There are 24/80 available cores.

Need to schedule job 24 using file 5. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 8200 8200 11200 ) 4 ( 8200 8264 11200 8200 8264 11200 8200 8264 11200 ) 5 ( 8200 8264 11200 8200 8264 11200 8200 8264 11200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Data 4 is on node 0.
Data 5 is on node 0.
Interval not empty, but is it on the node at time 8200 ?
Checking 8200 / 8264 / 11200.
Time to load file: 64.000000. Is being loaded? 1.
Score for job 24 is 8264 with node 0.
On node 1?
EAT is: 8200.
Data 1 is on node 1.
Data 2 is on node 1.
Data 3 is on node 1.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 24 is 8264 with node 1.
On node 2?
EAT is: 8200.
Data 1 is on node 2.
Data 2 is on node 2.
Data 3 is on node 2.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 24 is 8264 with node 2.
On node 3?
EAT is: 8200.
Data 1 is on node 3.
Data 2 is on node 3.
Data 3 is on node 3.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 24 is 8264 with node 3.
Job 24 using file 5 category 0 workload 1 will be computed on node 0 core(s) 6 start at time 8200 and is predicted to finish at time 11200.
There are 23/80 available cores.

Need to schedule job 25 using file 5. T = 8200
EAT == t.
HEFT SINGLE JOB
Intervals at time 8200 are:
Node 0: 1 ( ) 2 ( 8200 8200 8200 ) 3 ( 8200 8200 8200 8200 8200 11200 ) 4 ( 8200 8264 11200 8200 8264 11200 8200 8264 11200 ) 5 ( 8200 8264 11200 8200 8264 11200 8200 8264 11200 8200 8264 11200 )
Node 1: 1 ( ) 2 ( 8200 8200 8980 ) 3 ( 8200 8200 8200 )
Node 2: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
Node 3: 1 ( ) 2 ( 8200 8200 9480 ) 3 ( 8200 8200 8200 )
On node 0?
EAT is: 8200.
Data 1 is on node 0.
Data 2 is on node 0.
Data 3 is on node 0.
Data 4 is on node 0.
Data 5 is on node 0.
Interval not empty, but is it on the node at time 8200 ?
Checking 8200 / 8264 / 11200.
Time to load file: 64.000000. Is being loaded? 1.
Score for job 25 is 8264 with node 0.
On node 1?
EAT is: 8200.
Data 1 is on node 1.
Data 2 is on node 1.
Data 3 is on node 1.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 25 is 8264 with node 1.
On node 2?
EAT is: 8200.
Data 1 is on node 2.
Data 2 is on node 2.
Data 3 is on node 2.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 25 is 8264 with node 2.
On node 3?
EAT is: 8200.
Data 1 is on node 3.
Data 2 is on node 3.
Data 3 is on node 3.
Time to load file: 64.000000. Is being loaded? 0.
Score for job 25 is 8264 with node 3.
Job 25 using file 5 category 0 workload 1 will be computed on node 0 core(s) 7 start at time 8200 and is predicted to finish at time 11200.
End of reschedule.
Start of start_jobs at time 8200.
Adding data 3 on node 0 at time 8200.
For job 17 (delay = 2000): 0 transfer time and 0 waiting for a load time. Overhead is 0
==> Job 17 5 cores start at time 8200 on node 0 and will end at time 10200 before walltime: 1 transfer time is 0 data was 3.
Adding data 4 on node 0 at time 8200.
For job 18 (delay = 3000): 60 transfer time and 0 waiting for a load time. Overhead is 60
==> Job 18 1 cores start at time 8200 on node 0 and will end at time 11200 before walltime: 0 transfer time is 60 data was 4.
Adding data 4 on node 0 at time 8200.
For job 19 (delay = 3000): 0 transfer time and 60 waiting for a load time. Overhead is 60
==> Job 19 1 cores start at time 8200 on node 0 and will end at time 11200 before walltime: 0 transfer time is 0 data was 4.
Adding data 4 on node 0 at time 8200.
For job 20 (delay = 3000): 0 transfer time and 60 waiting for a load time. Overhead is 60
==> Job 20 1 cores start at time 8200 on node 0 and will end at time 11200 before walltime: 0 transfer time is 0 data was 4.
Adding data 5 on node 0 at time 8200.
For job 21 (delay = 3000): 60 transfer time and 0 waiting for a load time. Overhead is 60
==> Job 21 1 cores start at time 8200 on node 0 and will end at time 11200 before walltime: 0 transfer time is 60 data was 5.
Adding data 5 on node 0 at time 8200.
For job 22 (delay = 3000): 0 transfer time and 60 waiting for a load time. Overhead is 60
==> Job 22 1 cores start at time 8200 on node 0 and will end at time 11200 before walltime: 0 transfer time is 0 data was 5.
Adding data 5 on node 0 at time 8200.
For job 23 (delay = 3000): 0 transfer time and 60 waiting for a load time. Overhead is 60
==> Job 23 1 cores start at time 8200 on node 0 and will end at time 11200 before walltime: 0 transfer time is 0 data was 5.
Adding data 5 on node 0 at time 8200.
For job 24 (delay = 3000): 0 transfer time and 60 waiting for a load time. Overhead is 60
==> Job 24 1 cores start at time 8200 on node 0 and will end at time 11200 before walltime: 0 transfer time is 0 data was 5.
Adding data 5 on node 0 at time 8200.
For job 25 (delay = 3000): 0 transfer time and 60 waiting for a load time. Overhead is 60
==> Job 25 1 cores start at time 8200 on node 0 and will end at time 11200 before walltime: 0 transfer time is 0 data was 5.
Computing and writing results...
Scheduler: Mixed_strategy_if_EAT_is_t, Number of jobs evaluated: 25, Max queue time: 7050.000000, Mean queue time: 2404.399902, Total queue time: 60110.000000, Max flow: 9480.000000, Mean flow: 5261.200195, Total flow: 131530.000000, Transfer time: 9080.000000, Makespan: 11200.000000, Core time: 686100.000000, Waiting for a load time: 360.000000, Transfer + waiting time: 9440.000000, Mean flow stretch: 1.713527, Mean bounded flow stretch: 1.713527, Max flow stretch: 3.900862, Max bounded flow stretch: 3.900862, Nb of upgraded jobs: 0, Nb large queue times (>25000): 0, Mean flow stretch 128 256 1024: 1.655215 0.058312 0.000000, Mean flow stretch with a minimum 128 256 1024: 1.655215 0.058312 0.000000

