Slide 3: 
	Independant and homogeneous tasks
	Describe where is each task and make the link between the 2 figures

Slide 4:
	Talk about the goals but quickly
	
Slide 6:
	Formal goals
	
Slide 8:
	It computes the expected completion
	time of the first task in the queue on each GPU,
	based on a prediction of the time for transferring the data
	to the GPU (or communication time) comm and of the task
	computation time comp:
	Then, the task is allocated on the GPU where its completion time is minimal
	Here we consider the variant with the ready strategy.

Slide 9 : 
	A graph partitioner is very suitable to decompose a set of tasks sharing
	input data into several subsets of similar size while minimizing the number of common
	data among subsets. Each subset is then allocated to a GPU, and tasks
	within the subset are scheduled to further increase data
	locality. The fact that subsets have similar sizes ensures the load
	balancing among GPUs, while the minimization of common data reduces
	the amount of data that must be sent to several GPUs.
	On top of that
	We mostly used default parameters when calling
	hMETIS~\cite{hmetis}.
	Use the \emph{Ready} strategy of DMDAR to refine the schedule produced by hMETIS.
	Data transfers make some GPUs processing tasks faster than others, leading to load
	imbalance.  Thereby, we also implement dynamic load balancing using
	task stealing: when a GPU has terminated its allocated tasks and
	some other GPU still has work to do, the idle GPU steals half of the
	remaining tasks from the GPU with the most unprocessed tasks.


Slide 9: Ready from last slide

		\item Independant and homogeneous tasks 
		% A l'oral : (can be adapted to heterogeneous task)
		\item Same size data 
		% A l'oral : (again, can be adapted to data of different sizes)
		
Slide 10: Say that the selection of task will be precised on the next slide

Slide 12: explain Belady

Slide 14:
	
