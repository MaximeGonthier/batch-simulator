@inproceedings{Explicit_Control_in_a_Batch-Aware_Distributed_File_System,
  title={Explicit Control in the Batch-Aware Distributed File System.},
  author={Bent, John and Thain, Douglas and Arpaci-Dusseau, Andrea C and Arpaci-Dusseau, Remzi H and Livny, Miron},
  booktitle={NSDI},
  volume={4},
  pages={365--378},
  year={2004}
}

@inproceedings{loadbalance_and_trashing,
author = {Mills, Richard Tran and Stathopoulos, Andreas and Smirni, Evgenia},
title = {Algorithmic Modifications to the Jacobi-Davidson Parallel Eigensolver to Dynamically Balance External CPU and Memory Load},
year = {2001},
isbn = {158113410X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/377792.377903},
doi = {10.1145/377792.377903},
abstract = {Clusters of workstations (COWs) and SMPs have become popular and cost effective means of solving scientific problems. Because such environments may be heterogenous and/or time shared, dynamic load balancing is central to achieving high performance. Our thesis is that new levels of sophistication are required in parallel algorithm design and in the interaction of the algorithms with the runtime system. To support this thesis, we illustrate a novel approach for application-level balancing of external CPU and memory load on parallel iterative methods that employ some form of local preconditioning on each node. There are two key ideas. First, because all nodes need not perform their portion of the preconditioning phase to the same accuracy, the code can achieve perfect loadbalance, dynamically adapting to external CPU load, if we stop the preconditioning phase on all processors after a fixed amount of time. Second, if the program detects memory thrashing on a node, it recedes its preconditioning phase from that node, hopefully speeding the completion of competing jobs hence the relinquishing of their resources. We have implemented our load balancing approach in a state-of-the-art, coarse grain parallel Jacobi-Davidson eigensolver. Experimental results show that the new method adapts its algorithm based on runtime system information, without compromising the overall convergence behavior. We demonstrate the effectiveness of the new algorithm in a COW environment under (a) variable CPU load and (b) variable memory availability caused by competing applications.},
booktitle = {Proceedings of the 15th International Conference on Supercomputing},
pages = {454–463},
numpages = {10},
location = {Sorrento, Italy},
series = {ICS '01}
}

@inproceedings{minimize_network_contention,
  title={Communication-aware Job Scheduling using SLURM},
  author={Mishra, Priya and Agrawal, Tushar and Malakar, Preeti},
  booktitle={49th International Conference on Parallel Processing-ICPP: Workshops},
  pages={1--10},
  year={2020}
}

@article{Nikolopoulos2003AdaptiveSU,
  title={Adaptive scheduling under memory constraints on non-dedicated computationalfarms},
  author={Dimitrios S. Nikolopoulos and Constantine D. Polychronopoulos},
  journal={Future Gener. Comput. Syst.},
  year={2003},
  volume={19},
  pages={505-519}
}

@ARTICLE{Mammoth,  author={Shi, Xuanhua and Chen, Ming and He, Ligang and Xie, Xu and Lu, Lu and Jin, Hai and Chen, Yong and Wu, Song},  journal={IEEE Transactions on Parallel and Distributed Systems},   title={Mammoth: Gearing Hadoop Towards Memory-Intensive MapReduce Applications},   year={2015},  volume={26},  number={8},  pages={2300-2315},  doi={10.1109/TPDS.2014.2345068}}

@INPROCEEDINGS{issue_with_hdfs,
  author={Weets, Jean-François and Kakhani, Manish Kumar and Kumar, Anil},
  booktitle={2015 International Conference on Green Computing and Internet of Things (ICGCIoT)}, 
  title={Limitations and challenges of HDFS and MapReduce}, 
  year={2015},
  volume={},
  number={},
  pages={545-549},
  doi={10.1109/ICGCIoT.2015.7380524}}

@article{hdfs,
  title={HDFS architecture guide},
  author={Borthakur, Dhruba and others},
  journal={Hadoop apache project},
  volume={53},
  number={1-13},
  pages={2},
  year={2008}
}

@InProceedings{SLURM,
author="Yoo, Andy B.
and Jette, Morris A.
and Grondona, Mark",
editor="Feitelson, Dror
and Rudolph, Larry
and Schwiegelshohn, Uwe",
title="SLURM: Simple Linux Utility for Resource Management",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="44--60",
abstract="A new cluster resource management system called Simple Linux Utility Resource Management (SLURM) is described in this paper. SLURM, initially developed for large Linux clusters at the Lawrence Livermore National Laboratory (LLNL), is a simple cluster manager that can scale to thousands of processors. SLURM is designed to be flexible and fault-tolerant and can be ported to other clusters of different size and architecture with minimal effort. We are certain that SLURM will benefit both users and system architects by providing them with a simple, robust, and highly scalable parallel job execution environment for their cluster system.",
isbn="978-3-540-39727-4"
}

@article{New_Backfill,
title = {Introducing New Backfill-based Scheduler for SLURM Resource Manager},
journal = {Procedia Computer Science},
volume = {66},
pages = {661-669},
year = {2015},
note = {4th International Young Scientist Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.11.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915034249},
author = {Sergei Leonenkov and Sergey Zhumatiy},
keywords = {SLURM, supercomputer, scheduling algorithms, backfill},
abstract = {The work proposes a design for a new external scheduler for SLURM (Simple Linux Utility for Resource Management). Schedulers, included in SLURM by default are good enough for many sites, but big supercomputers serving many users meet limitations of standard SLURM schedulers. In this work we discover methods to break these limitations via implementing new portable SLURM scheduler. We address the problem of maximizing the number of users, whose requests are processed in each given moment of time, and decrease start time of user's first task. Our approach is based on standard backfill algorithm and includes additional features, such as simplification of SLURM priority system, replacing slow SQL-based accounting checks by faster ACL checks and upgrading cluster administration convenience.}
}

@InProceedings{Maui_Scheduler,
author="Jackson, David
and Snell, Quinn
and Clement, Mark",
editor="Feitelson, Dror G.
and Rudolph, Larry",
title="Core Algorithms of the Maui Scheduler",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="87--102",
abstract="The Maui scheduler has received wide acceptance in the HPC community as a highly configurable and effective batch scheduler. It is currently in use on hundreds of SP, O2K, and Linux cluster systems throughout the world including a high percentage of the largest and most cutting edge research sites. While the algorithms used within Maui have proven themselves effective, nothing has been published to date documenting these algorithms nor the configurable aspects they support. This paper focuses on three areas of Maui scheduling, specifically, backfill, job prioritization, and fairshare. It briefly discusses the goals of each component, the issues and corresponding design decisions, and the algorithms enabling the Maui policies. It also covers the configurable aspects of each algorithm and the impact of various parameter selections.",
isbn="978-3-540-45540-0"
}

@InProceedings{Batsim,
author="Dutot, Pierre-Fran{\c{c}}ois
and Mercier, Michael
and Poquet, Millian
and Richard, Olivier",
editor="Desai, Narayan
and Cirne, Walfredo",
title="Batsim: A Realistic Language-Independent Resources and Jobs Management Systems Simulator",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="178--197",
abstract="As large scale computation systems are growing to exascale, Resources and Jobs Management Systems (RJMS) need to evolve to manage this scale modification. However, their study is problematic since they are critical production systems, where experimenting is extremely costly due to downtime and energy costs. Meanwhile, many scheduling algorithms emerging from theoretical studies have not been transferred to production tools for lack of realistic experimental validation. To tackle these problems we propose Batsim, an extendable, language-independent and scalable RJMS simulator. It allows researchers and engineers to test and compare any scheduling algorithm, using a simple event-based communication interface, which allows different levels of realism. In this paper we show that Batsim's behaviour matches the one of the real RJMS OAR. Our evaluation process was made with reproducibility in mind and all the experiment material is freely available.",
isbn="978-3-319-61756-5"
}

@INPROCEEDINGS{easybf,
  author={Wong, Adam K.L. and Goscinski, Andrzej M.},
  booktitle={2007 IEEE International Conference on Cluster Computing}, 
  title={Evaluating the EASY-backfill job scheduling of static workloads on clusters}, 
  year={2007},
  volume={},
  number={},
  pages={64-73},
  doi={10.1109/CLUSTR.2007.4629218}}

