@inproceedings{Explicit_Control_in_a_Batch-Aware_Distributed_File_System,
  title={Explicit Control in the Batch-Aware Distributed File System.},
  author={Bent, John and Thain, Douglas and Arpaci-Dusseau, Andrea C and Arpaci-Dusseau, Remzi H and Livny, Miron},
  booktitle={NSDI},
  volume={4},
  pages={365--378},
  year={2004}
}

@inproceedings{loadbalance_and_trashing,
author = {Mills, Richard Tran and Stathopoulos, Andreas and Smirni, Evgenia},
title = {Algorithmic Modifications to the Jacobi-Davidson Parallel Eigensolver to Dynamically Balance External CPU and Memory Load},
year = {2001},
isbn = {158113410X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/377792.377903},
doi = {10.1145/377792.377903},
abstract = {Clusters of workstations (COWs) and SMPs have become popular and cost effective means of solving scientific problems. Because such environments may be heterogenous and/or time shared, dynamic load balancing is central to achieving high performance. Our thesis is that new levels of sophistication are required in parallel algorithm design and in the interaction of the algorithms with the runtime system. To support this thesis, we illustrate a novel approach for application-level balancing of external CPU and memory load on parallel iterative methods that employ some form of local preconditioning on each node. There are two key ideas. First, because all nodes need not perform their portion of the preconditioning phase to the same accuracy, the code can achieve perfect loadbalance, dynamically adapting to external CPU load, if we stop the preconditioning phase on all processors after a fixed amount of time. Second, if the program detects memory thrashing on a node, it recedes its preconditioning phase from that node, hopefully speeding the completion of competing jobs hence the relinquishing of their resources. We have implemented our load balancing approach in a state-of-the-art, coarse grain parallel Jacobi-Davidson eigensolver. Experimental results show that the new method adapts its algorithm based on runtime system information, without compromising the overall convergence behavior. We demonstrate the effectiveness of the new algorithm in a COW environment under (a) variable CPU load and (b) variable memory availability caused by competing applications.},
booktitle = {Proceedings of the 15th International Conference on Supercomputing},
pages = {454–463},
numpages = {10},
location = {Sorrento, Italy},
series = {ICS '01}
}

@INPROCEEDINGS{oar,  author={Capit, N. and Da Costa, G. and Georgiou, Y. and Huard, G. and Martin, C. and Mounie, G. and Neyron, P. and Richard, O.},  booktitle={CCGrid 2005. IEEE International Symposium on Cluster Computing and the Grid, 2005.},   title={A batch scheduler with high level components},   year={2005},  volume={2},  number={},  pages={776-783 Vol. 2},  doi={10.1109/CCGRID.2005.1558641}}

@inproceedings{minimize_network_contention,
  title={Communication-aware Job Scheduling using SLURM},
  author={Mishra, Priya and Agrawal, Tushar and Malakar, Preeti},
  booktitle={49th International Conference on Parallel Processing-ICPP: Workshops},
  pages={1--10},
  year={2020}
}

@article{Nikolopoulos2003AdaptiveSU,
  title={Adaptive scheduling under memory constraints on non-dedicated computationalfarms},
  author={Dimitrios S. Nikolopoulos and Constantine D. Polychronopoulos},
  journal={Future Gener. Comput. Syst.},
  year={2003},
  volume={19},
  pages={505-519}
}

@INPROCEEDINGS{Optimizing_load_balancing_and_data_locality_with_data_aware_scheduling,
  author={Wang, Ke and Zhou, Xraobing and Li, Tonglin and Zhao, Dongfang and Lang, Michael and Raicu, Ioan},
  booktitle={2014 IEEE International Conference on Big Data (Big Data)}, 
  title={Optimizing load balancing and data-locality with data-aware scheduling}, 
  year={2014},
  volume={},
  number={},
  pages={119-128},
  doi={10.1109/BigData.2014.7004220}}

@article{Scheduling_Shared_Scans_of_Large_Data_Files,
author = {Agrawal, Parag and Kifer, Daniel and Olston, Christopher},
title = {Scheduling Shared Scans of Large Data Files},
year = {2008},
issue_date = {August 2008},
publisher = {VLDB Endowment},
volume = {1},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/1453856.1453960},
doi = {10.14778/1453856.1453960},
abstract = {We study how best to schedule scans of large data files, in the presence of many simultaneous requests to a common set of files. The objective is to maximize the overall rate of processing these files, by sharing scans of the same file as aggressively as possible, without imposing undue wait time on individual jobs. This scheduling problem arises in batch data processing environments such as Map-Reduce systems, some of which handle tens of thousands of processing requests daily, over a shared set of files.As we demonstrate, conventional scheduling techniques such as shortest-job-first do not perform well in the presence of cross-job sharing opportunities. We derive a new family of scheduling policies specifically targeted to sharable workloads. Our scheduling policies revolve around the notion that, all else being equal, it is good to schedule nonsharable scans ahead of ones that can share IO work with future jobs, if the arrival rate of sharable future jobs is expected to be high. We evaluate our policies via simulation over varied synthetic and real workloads, and demonstrate significant performance gains compared with conventional scheduling approaches.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {958–969},
numpages = {12}
}

@InProceedings{gang_scheduling,
author="Feitelson, Dror G.
and Jettee, Morris A.",
editor="Feitelson, Dror G.
and Rudolph, Larry",
title="Improved utilization and responsiveness with gang scheduling",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="1997",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="238--261",
abstract="Most commercial multicomputers use space-slicing schemes in which each scheduling decision has an unknown impact on the future: should a job be scheduled, risking that it will block other larger jobs later, or should the processors be left idle for now in anticipation of future arrivals? This dilemma is solved by using gang scheduling, because then the impact of each decision is limited to its time slice, and future arrivals can be accommodated in other time slices. This added flexibility is shown to improve overall system utilization and responsiveness. Empirical evidence from using gang scheduling on a Cray T3D installed at Lawrence Livermore National Lab corroborates these results, and shows conclusively that gang scheduling can be very effective with current technology.",
isbn="978-3-540-69599-8"
}

@ARTICLE{Mammoth,  author={Shi, Xuanhua and Chen, Ming and He, Ligang and Xie, Xu and Lu, Lu and Jin, Hai and Chen, Yong and Wu, Song},  journal={IEEE Transactions on Parallel and Distributed Systems},   title={Mammoth: Gearing Hadoop Towards Memory-Intensive MapReduce Applications},   year={2015},  volume={26},  number={8},  pages={2300-2315},  doi={10.1109/TPDS.2014.2345068}}

@inproceedings{torque,
author = {Staples, Garrick},
title = {TORQUE Resource Manager},
year = {2006},
isbn = {0769527000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1188455.1188464},
doi = {10.1145/1188455.1188464},
abstract = {With TORQUE Resource Manager now reaching over 10,000 downloads per month and use across thousands of leading sites representing commercial, government, and academic organizations, we invite all TORQUE users to meet and discuss TORQUE with the professional developers, community volunteers other members who use and have contributed to the TORQUE project.Here we will discuss the current state of TORQUE including some of the more recent enhancements and capabilities along with the road map for the upcoming year. We will also provide a time for TORQUE users to share experiences, best practices, and new needs.},
booktitle = {Proceedings of the 2006 ACM/IEEE Conference on Supercomputing},
pages = {8–es},
location = {Tampa, Florida},
series = {SC '06}
}

@INPROCEEDINGS{issue_with_hdfs,
  author={Weets, Jean-François and Kakhani, Manish Kumar and Kumar, Anil},
  booktitle={2015 International Conference on Green Computing and Internet of Things (ICGCIoT)}, 
  title={Limitations and challenges of HDFS and MapReduce}, 
  year={2015},
  volume={},
  number={},
  pages={545-549},
  doi={10.1109/ICGCIoT.2015.7380524}}

@article{hdfs,
  title={HDFS architecture guide},
  author={Borthakur, Dhruba and others},
  journal={Hadoop apache project},
  volume={53},
  number={1-13},
  pages={2},
  year={2008}
}

@InProceedings{SLURM,
author="Yoo, Andy B.
and Jette, Morris A.
and Grondona, Mark",
editor="Feitelson, Dror
and Rudolph, Larry
and Schwiegelshohn, Uwe",
title="SLURM: Simple Linux Utility for Resource Management",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2003",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="44--60",
abstract="A new cluster resource management system called Simple Linux Utility Resource Management (SLURM) is described in this paper. SLURM, initially developed for large Linux clusters at the Lawrence Livermore National Laboratory (LLNL), is a simple cluster manager that can scale to thousands of processors. SLURM is designed to be flexible and fault-tolerant and can be ported to other clusters of different size and architecture with minimal effort. We are certain that SLURM will benefit both users and system architects by providing them with a simple, robust, and highly scalable parallel job execution environment for their cluster system.",
isbn="978-3-540-39727-4"
}

@article{New_Backfill,
title = {Introducing New Backfill-based Scheduler for SLURM Resource Manager},
journal = {Procedia Computer Science},
volume = {66},
pages = {661-669},
year = {2015},
note = {4th International Young Scientist Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.11.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915034249},
author = {Sergei Leonenkov and Sergey Zhumatiy},
keywords = {SLURM, supercomputer, scheduling algorithms, backfill},
abstract = {The work proposes a design for a new external scheduler for SLURM (Simple Linux Utility for Resource Management). Schedulers, included in SLURM by default are good enough for many sites, but big supercomputers serving many users meet limitations of standard SLURM schedulers. In this work we discover methods to break these limitations via implementing new portable SLURM scheduler. We address the problem of maximizing the number of users, whose requests are processed in each given moment of time, and decrease start time of user's first task. Our approach is based on standard backfill algorithm and includes additional features, such as simplification of SLURM priority system, replacing slow SQL-based accounting checks by faster ACL checks and upgrading cluster administration convenience.}
}

@InProceedings{Maui_Scheduler,
author="Jackson, David
and Snell, Quinn
and Clement, Mark",
editor="Feitelson, Dror G.
and Rudolph, Larry",
title="Core Algorithms of the Maui Scheduler",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="87--102",
abstract="The Maui scheduler has received wide acceptance in the HPC community as a highly configurable and effective batch scheduler. It is currently in use on hundreds of SP, O2K, and Linux cluster systems throughout the world including a high percentage of the largest and most cutting edge research sites. While the algorithms used within Maui have proven themselves effective, nothing has been published to date documenting these algorithms nor the configurable aspects they support. This paper focuses on three areas of Maui scheduling, specifically, backfill, job prioritization, and fairshare. It briefly discusses the goals of each component, the issues and corresponding design decisions, and the algorithms enabling the Maui policies. It also covers the configurable aspects of each algorithm and the impact of various parameter selections.",
isbn="978-3-540-45540-0"
}

@InProceedings{Batsim,
author="Dutot, Pierre-Fran{\c{c}}ois
and Mercier, Michael
and Poquet, Millian
and Richard, Olivier",
editor="Desai, Narayan
and Cirne, Walfredo",
title="Batsim: A Realistic Language-Independent Resources and Jobs Management Systems Simulator",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="178--197",
abstract="As large scale computation systems are growing to exascale, Resources and Jobs Management Systems (RJMS) need to evolve to manage this scale modification. However, their study is problematic since they are critical production systems, where experimenting is extremely costly due to downtime and energy costs. Meanwhile, many scheduling algorithms emerging from theoretical studies have not been transferred to production tools for lack of realistic experimental validation. To tackle these problems we propose Batsim, an extendable, language-independent and scalable RJMS simulator. It allows researchers and engineers to test and compare any scheduling algorithm, using a simple event-based communication interface, which allows different levels of realism. In this paper we show that Batsim's behaviour matches the one of the real RJMS OAR. Our evaluation process was made with reproducibility in mind and all the experiment material is freely available.",
isbn="978-3-319-61756-5"
}

@INPROCEEDINGS{easybf,
  author={Wong, Adam K.L. and Goscinski, Andrzej M.},
  booktitle={2007 IEEE International Conference on Cluster Computing}, 
  title={Evaluating the EASY-backfill job scheduling of static workloads on clusters}, 
  year={2007},
  volume={},
  number={},
  pages={64-73},
  doi={10.1109/CLUSTR.2007.4629218}}

@misc{slurm_website_scheduling,
	title="Slurm Workload manager",
	howpublished="\url{https://slurm.schedmd.com/sched_config.html}",
	note = {Accessed: 2022-12-06}}
	
@misc{plafrim,
	title="PlaFRIM Users Documentation",
	howpublished="\url{https://plafrim-users.gitlabpages.inria.fr/doc/#slurm}",
	note = {Accessed: 2022-12-06}}
	
@InProceedings{maui,
author="Jackson, David
and Snell, Quinn
and Clement, Mark",
editor="Feitelson, Dror G.
and Rudolph, Larry",
title="Core Algorithms of the Maui Scheduler",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2001",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="87--102",
abstract="The Maui scheduler has received wide acceptance in the HPC community as a highly configurable and effective batch scheduler. It is currently in use on hundreds of SP, O2K, and Linux cluster systems throughout the world including a high percentage of the largest and most cutting edge research sites. While the algorithms used within Maui have proven themselves effective, nothing has been published to date documenting these algorithms nor the configurable aspects they support. This paper focuses on three areas of Maui scheduling, specifically, backfill, job prioritization, and fairshare. It briefly discusses the goals of each component, the issues and corresponding design decisions, and the algorithms enabling the Maui policies. It also covers the configurable aspects of each algorithm and the impact of various parameter selections.",
isbn="978-3-540-45540-0"
}

@inproceedings{Characterization_of_Backfilling,
author = {Srinivasan, Srividya and Kettimuthu, Raj and Subramani, Vijay and Sadayappan, Ponnuswamy},
year = {2002},
month = {02},
pages = {514 - 519},
title = {Characterization of Backfilling Strategies for Parallel Job Scheduling},
isbn = {0-7695-1680-7},
doi = {10.1109/ICPPW.2002.1039773}
}

@article{Introducing-New-Backfill-based,
title = {Introducing New Backfill-based Scheduler for SLURM Resource Manager},
journal = {Procedia Computer Science},
volume = {66},
pages = {661-669},
year = {2015},
note = {4th International Young Scientist Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.11.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915034249},
author = {Sergei Leonenkov and Sergey Zhumatiy},
keywords = {SLURM, supercomputer, scheduling algorithms, backfill},
abstract = {The work proposes a design for a new external scheduler for SLURM (Simple Linux Utility for Resource Management). Schedulers, included in SLURM by default are good enough for many sites, but big supercomputers serving many users meet limitations of standard SLURM schedulers. In this work we discover methods to break these limitations via implementing new portable SLURM scheduler. We address the problem of maximizing the number of users, whose requests are processed in each given moment of time, and decrease start time of user's first task. Our approach is based on standard backfill algorithm and includes additional features, such as simplification of SLURM priority system, replacing slow SQL-based accounting checks by faster ACL checks and upgrading cluster administration convenience.}
}
