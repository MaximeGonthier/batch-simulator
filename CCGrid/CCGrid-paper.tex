% 10 pages, excluding references
% Abstract 25/11
% Paper 02/12
% CCGrid will be following a double-blind review process
% IEEE two-column conference proceedings template

\documentclass[conference,10pt]{IEEEtran}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsfonts, colortbl, xspace, todonotes, paralist, multirow, hyperref}
\hypersetup{
   colorlinks=false,
   pdfborder={0 0 0},
}
\usepackage[english]{babel}
\usepackage{graphicx, color, amssymb, url, xcolor, tikz, pgf, float, subcaption, algorithm,  tabularx}
\usepackage[noend]{algpseudocode}
\usetikzlibrary{trees, shapes, calc, external, fit, arrows, decorations, decorations.pathreplacing, patterns, automata, positioning, arrows.meta}

% Custom commands
\algnewcommand\algorithmicforeach{\textbf{for each}}
\algdef{S}[FOR]{ForEach}[1]{\algorithmicforeach\ #1\ \algorithmicdo}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\newcommand{\Node}[1]{\ensuremath{\mathrm{Node}_{#1}}\xspace}
\newcommand{\flow}[1]{\ensuremath{\mathit{flow}_{#1}}\xspace}
\newcommand{\file}{\ensuremath{\mathit{File}}\xspace}
\newcommand{\memory}{\ensuremath{\mathit{Mem}}\xspace}
\newcommand{\memorymap}{\ensuremath{\mathcal{M}_{map}}\xspace}
\newcommand{\duration}{\mathit{Duration}\xspace}
\newcommand{\bandwidth}{\mathit{BW}\xspace}
\newcommand{\core}{\mathit{Cores}\xspace}
\newcommand{\submissiontime}{\mathit{Subtime}\xspace}
\newcommand{\walltime}{\mathit{Walltime}\xspace}
\newcommand{\completiontime}{\mathit{Completiontime}\xspace}
\newcommand{\start}{\mathit{Starttime}\xspace}
\newcommand{\fileset}{\ensuremath{\mathbb{F}}\xspace}
\newcommand{\jobset}{\ensuremath{\mathbb{J}}\xspace}
\newcommand{\nodeset}{\ensuremath{\mathbb{N}}\xspace}
\newcommand{\evict}{\ensuremath{\mathcal{V}}\xspace}
\newcommand{\nbloads}{\ensuremath{\mathit{\mathit{Loads}}}\xspace}
\newcommand{\live}{\ensuremath{L}\xspace}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{document}

\title{Locality-aware batch scheduling on I/O intensive workloads}

\maketitle

\begin{abstract}
Schedulers proposed by resource manager like SLURM or OAR are
efficient enough for a classical use of a cluster. However, 
users may submits tens to hundreds jobs using the same multi-GB input file.
The sum of these communications, adds significant queue times for
all subsequent jobs. Users could manually group together input files into a 
single job to reduce the effects from I/O reads. However, to offer more
flexibility to the users and avoid jobs monopolizing a large number of nodes,
we would like to let users submit jobs the way they want and schedule efficiently
those jobs on our nodes. The workers have a way to store files
(with a limit on the memory size). Thus, a way to minimize data transfers
is to schedule jobs using identical files on the same set of nodes.
We present in this paper, three schedulers that \textbf{take into consideration data locality
to minimize data transfers and thus reduce the mean waiting time of a job}.

We present three schedulers able to \textbf{distribute the load
between the workers as well as having a vision of what the memory of each worker
contains in order to re-use as much as possible an input file already loaded on a worker's
local memory}.
Experiments were performed using real cluster's history (\todo[inline]{Max: Can we talk about Rackham in double blind?}) allowing us to replicate the behavior of real users.

We also persent \todo[inline]{Max: Other contributions?}
\end{abstract}

\begin{IEEEkeywords}
batch scheduling, Jobs sharing inputs, Real workload, Data-aware, Job scheduling, Communication-aware, Batch systems\todo[inline]{Max: I've added a lot of keywords, we should only choose a few of those I think?}
\end{IEEEkeywords}

\todo[inline]{Maxime: Do not hesitate to add a lot of todo notes.}

\section{Introduction}\label{sec.introduction}

\section{Related Work - Draft}\label{sec.related_work}

\paragraph{Scheduling jobs on large clusters}

To schedule jobs on batch systems, two systems are prominent: SLURM~\cite{SLURM} and OAR~\cite{oar}.
SLURM is used on most HPC clusters. It's default strategy to schedule jobs is
to prioritize jobs by their submission time, in other words a First-Come First-Serve strategy
(or FCFS)\footnote{{\scriptsize\url{https://slurm.schedmd.com/sched_config.html}}}.

On top of that, a backfilling algorithm is often used~\cite{New_Backfill}.
%~ Backfilling is, most often, based on the First Come - First Served principle as well.
%~ While the scheduler is running, jobs in the queue are sorted by priority and queuing time~\cite{New_Backfill}.
%~ Then, the backfilling will start immediately all jobs that can be started and completed without delaying the planned schedule.
%~ This algorithm allows to increase the density of supercomputer ressources' use by 20\% as well as reducing the average waiting time
%~ for execution~\cite{Maui_Scheduler}.
%~ There are two types of backfills. Conservative and EASY. Conservative backfill jobs that do not delay all other jobs. EASY backfill jobs that do not delay only the first scheduled job.

\paragraph{Improving SLURM and other batch systems' schedulers}

To deal with communication-intensive jobs on SLURM, a solution can be to
minimize network contention by allocating nodes on the least
contended nodes and switches~\cite{minimize_network_contention}. 
In our model we are not studying the network topology and consider independant nodes.
Moreover, this requires a tree-based network topologies, which is different from our modem.
Furthermore, we are scheduling further down the topology (i.e nodes and not switches).

Batch-Aware Distributed File System~\cite{Explicit_Control_in_a_Batch-Aware_Distributed_File_System},
are a system designed to orchestrate large, I/O-intensive batch workloads on remote computing clusters.
It adds storage servers that export access to the disk.
They use detailed knowledge of workload characteristics.
However, the main idea is not data reuse but to
facilitates the execution of I/O intensive batch
jobs by selecting appropriate storage policies
in regards to I/O scoping (creating a custom environment for each job
for data that will be used a lot by the job, thus not accessing the main disk too
much) and space allocation.


\subsection{Other papers about memory-aware scheduling}
Memory-aware scheduling on clusters have been studied in the past.
 
%~ "Algorithmic Modifications to the
%~ Jacobi-Davidson Parallel Eigensolver to Dynamically Balance External CPU and Memory Load"~\cite{loadbalance_and_trashing} tackle both load balancing and memory constraint. For the load balancing, they 
%~ estimate the time needed by the fastest processor to perform the required $m$ jobs. Thus they can equilibrate the load
%~ with this information. In our study we could use a similar strategy by estimating the 
%~ processing time of a job, the length of a file transfer, and the amount of file transfers needed.
%~ To deal with memory constraint the strategy applied in the paper is to check if 
%~ nodes are thrashing data. If yes, it will recede execution of jobs on this node.
%~ The main differences are that they are using dynamic jobs. Also, we would like to 
%~ manage eviction and optimize data reuse during the scheduling phase, instead of
%~ receding execution on nodes.

Some researchers~\cite{Nikolopoulos2003AdaptiveSU}
are focusing on a better utilization of idling memory together with 
thrashing limitation. Our focus will be to control data loads and eviction so the
processing order will naturally limits thrashing.

\subsection{HDFS, a popular distributed file system - Draft, I need to double check my sources}
HDFS~\cite{hdfs} or Hadoop Distributed File System is a distributed file system that
incorporate memory-aware scheduling. HDFS is particularly used for applications that have large data sets. 
%~ "Moving Computation is Cheaper than Moving Data" is an important idea for HDFS.
It migrates a computation closer to where the data is located rather than moving the data to where
the application is running.
%~ Here are our main differences with HDFS. Firstly, HDFS is made for commodity hardware, prone
%~ to more errors and breakdown, so to minimize the risk of failure, data are redundant on the nodes.
HDFS is made for commodity(?) hardware, where errors need to be minimized. Thus, data are redundant
to avoid breakdowns.
In our use case, the scheduler will run on professional clusters and the main point is to load as 
little data as possible. 
Secondly, HDFS is mainly a storage system, with an historic on files locations.
It is not relevant in our use case. 
Thirdly, the scheduling can have issues. A paper describe in detail some problems from MapReduce~\cite{issue_with_hdfs}, the
programming language used in HFDS: the static configuration of the memory allocation, the one-task assigned buffers, the
lake of concurrent task running strategy and the I/O negative impact in memory during the shuffling phase.
To resolve these issues, Mammoth~\cite{Mammoth} was created. It optimize memory usage on a node depending on the hardware configuration.
Our approach is different because we are not dealing with MapReduce or memory allocation.
Our approach is upstream. We can only allocate jobs to nodes. Moreover, we would like to maintain
%~ equity among users  while optimizing I/O.
In addition, HDFS is particularly efficient when the input data used are identical over time.
In our case, one user will submit a lot of different jobs using the same data, but between users,
the inputs are not the same. So HDFS would be less efficient.

\section{Framework - Draft}\label{sec.framework}

We consider the problem of scheduling a set of independent jobs $\jobset = {J_1, J_2, ..., J_k}$ on
a set of independent nodes $\nodeset = {\Node{1}, \Node{2}, ..., \Node{l}}$.

Each node is equipped with $m$ cores noted: $\Node{1}(C_1, C_2, ..., C_m)$.

%~ Let's note $\mathbb{M} = M_1, M_2, ..., M_o$ the set of available memory sizes, with $M_1 < M_2 < ... < M_o$.
%~ Each node has a limited memory $\memory(\Node{i})$ such that $\memory(\Node{i}) \in \mathbb{M}$.

We denote by $\fileset = F_1, F_2, ..., F_n$ the set of input files.
Each file has a size in GB noted $\memory(F_i)$.
The size of a file is proportional to the number of cores requested by the job using the file.
This size is thus a multiple of $\frac{M_i}{\core(J_j)}$, $M_i \in \mathbb{M}$.

Each job is equipped with the folowing attributes:
\begin{itemize}
	\item A number of required cores $\core(J_i)$ such as $1 \leq \core(J_i) \leq 20$.
	\item An input file $\file(J_i) \in \fileset$.
	\item A submission time $\submissiontime(J_i)$.
	\item A walltime $\walltime(J_i)$ corresponding to the maximum time during which $J_i$ can run on a node.
\end{itemize}

We are in a non-preemptive case, meaning that a job cannot be stopped and resumed.
\todo[inline]{Max: I'm not sure where this sentence should go.}

\section{Schedulers - Draft}\label{sec.schedulers}

In this section, we present the various schedulers used to solve
the partitioning problem presented above. 

Some of these methods uses start or completion time as a way to
schedule each job (section~\ref{subsec.fcfs_eft}) while another compute 
a score to choose the best node (section~\ref{subsec.score}) and others
ar mixed strategy between these two (sections~\ref{subsec.mixed} and~\ref{subsec.opportunistic}).

\subsection{Our two baseline schedulers: FCFS and EFT}\label{subsec.fcfs_eft}

Under our model, a fair baseline would be a scheduler capable
of reducing file transfers while keeping the First-Come First-Serve 
principle. This scheduler is Earliest Finish Time (or EFT).
It's an enhanced version of FCFS which chooses to schedule a job
on the node with the earliest available finish time, thus considering
the time to load the file, and consequently choosing nodes where a file will
be re-used. 

\begin{algorithm}[htbp]
	\caption{Earliest Finish Time (EFT)}\label{algo.eft}
	\begin{algorithmic}[1]
		\For{$J_i \in \jobset$}
			\State Schedule $J_i$ on the node with the earliest completion time.
		\EndFor
	\end{algorithmic}
\end{algorithm}

Coupled with it, we add the conservative backfilling strategy mentioned earlier:

\subsection{A locality-focused algorithm: SCORE\todo{Max: Or another name}}

The previous strategies are focusing on starting as soon as possible (FCFS)
of finishing as soon as possible a job (EFT).
Those are good methods to avoid starvation of a node and reduce queue times.
However, they are ignoring the effect multiplying the number of copy of a file
over multiple nodes. Indeed, selecting different nodes for jobs using a common
file will increase file loads in order to minimize immediate queue times.
Our strategy (called SCORE) aims at favoring locality in order to reduce
queue times in the long run by reusing the same files. 

The main principle of our algorithm detailed in Algorithm~\ref{algo.score} 
is to find a balance between the earliest available time and data locality,
with a tiebreak on data eviction. A score composed of the earliest available 
time, the time to load or wait for the files to be available and the cost of 
reloading evicted files is computed for each node. The job is then scheduled
on the node with the lowest score.

\begin{algorithm}[htbp]\caption{SCORE (Draft)}\label{algo.score}\begin{algorithmic}[1]
	\Statex For each job $J_i$ in the queue
	\State $B\_multiplier \gets 500$
	\State $C\_multiplier \gets 1$
	\ForEach {$\Node{k} \in \nodeset$}
		\State $A \gets$ the earliest available time to compute $J_i$ on $\Node{k}$
		\State $B \gets$ the time to load $\file(J_i)$ on $\Node{k}$ at time $A$ \Comment{Or time waiting for the file to be loaded by another job.}
		%~ \State $C \gets (\memory(\file(\Node{k})~that~end~before~A) \times \frac{\core(J_i)}{\core(\Node{k})})/\bandwidth$
		\State Let $\mathit{sub\_J}$ be the subset of jobs that ends right before time $A$ on $\Node{k}$
		\State $C \gets (\file(\mathit{sub\_J}) \times \frac{\core(J_i)}{\core(\Node{k})})/\bandwidth$
		\State $score_{\Node{k}} \gets A + B\_multiplier \times B + C\_multiplier \times C$
	\EndFor
	\State Schedule $J_i$ on the node with the smallest score. Tiebreak with lowest node's id.
\end{algorithmic}\end{algorithm}

\begin{algorithm}[htbp]
\caption{EFT-SCORE MIX (Draft)}
\hspace*{\algorithmicindent} \textbf{Input: Set of queued jobs $\jobset$. Set of nodes $\nodeset$.}
\begin{algorithmic}[1]
\State $occupation\_threshold \gets 80$ 
\State $occupation \gets$ the percentage of nodes running at least one job
%~ \ForEach {$J_i \in \jobset$}
	\If{$occupation < occupation\_threshold$}
		\State $EFT(\jobset,\nodeset)$
	\Else
		\State $SCORE(\jobset,\nodeset)$
	\EndIf
%~ \EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[htbp]
\caption{OPPORTUNISTIC-SCORE MIX (Draft)}
\hspace*{\algorithmicindent} \textbf{Input: Set of queued jobs $\jobset$. Set of nodes $\nodeset$.}
\begin{algorithmic}[1]
\ForEach {$J_i \in \jobset$}
	\State $B\_multiplier \gets 500$
	\State $C\_multiplier \gets 1$
	\ForEach {$\Node{k} \in \nodeset$}
		\State $A \gets$ the earliest available time to compute $J_i$ on $\Node{k}$
		\If{$A = current~time$}
			\State $B\_multiplier \gets 1$
			\State $C\_multiplier \gets 0$
		\EndIf
		\State $B \gets$ the time to load $\file(J_i)$ on $\Node{k}$ at time $A$
		%~ \State $C \gets (\memory(\file(\Node{k})~that~end~before~A) \times \frac{\core(J_i)}{\core(\Node{k})})/\bandwidth$
		\State Let $\mathit{sub\_J}$ be the subset of jobs that ends right before time $A$ on $\Node{k}$
		\State $C \gets (\file(\mathit{sub\_J}) \times \frac{\core(J_i)}{\core(\Node{k})})/\bandwidth$
		\State $score_{\Node{k}} \gets A + B\_multiplier \times B + C\_multiplier \times C$
	\EndFor
	\State Schedule $J_i$ on the node with the smallest score. Schedule on the node with the lowest index in case of a tie.
	%~ \State Remove $J_i$ from $\jobset$
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[htbp]
\caption{SCORE CONSERVATIVE BF (Draft)}
\hspace*{\algorithmicindent} \textbf{Input: Set of queued jobs $\jobset$. Set of nodes $\nodeset$.}
\begin{algorithmic}[1]
\State $B\_multiplier \gets 500$
\State $C\_multiplier \gets 1$
\ForEach {$J_i \in \jobset$}
	\ForEach {$\Node{k} \in \nodeset$}
		\State $A \gets$ the earliest available time to compute $J_i$ on $\Node{k}$
		\State $B \gets$ the time to load $\file(J_i)$ on $\Node{k}$ at time $A$
		\State Let $\mathit{sub\_J}$ be the subset of jobs that ends right before time $A$ on $\Node{k}$
		\State $C \gets (\file(\mathit{sub\_J}) \times \frac{\core(J_i)}{\core(\Node{k})})/\bandwidth$
		\State $score_{\Node{k}} \gets A + B\_multiplier \times B + C\_multiplier \times C$
		\If {$\Node{k}$ has a hole and $j_i$ can use it}
			\State $A \gets current~time$
			\State $B \gets$ the time to load $\file(J_i)$ on $\Node{k}$ at time $A$
			\State Let $\mathit{sub\_J}$ be the subset of jobs that ends right before time $A$ on $\Node{k}$
			\State $C \gets (\file(\mathit{sub\_J}) \times \frac{\core(J_i)}{\core(\Node{k})})/\bandwidth$
			\State $score_{\mathit{Cores\_Hole}(\Node{k})} \gets A + B\_multiplier \times B + C\_multiplier \times C$
		\EndIf
	\EndFor
	\State Schedule $J_i$ on the node or hole with the best score. Schedule on the node with the lowest index in case of a tie.
	\If {$Backfill\_mode = 1$ OR $Backfill\_mode = 2$}
		\State Minimize hole creation when affecting cores to $j_i$
		\If {$Backfill\_mode = 1$}
			\State Schedule $j_i$ on the cores with the biggest next start time
		\Else
			\State Schedule $j_i$ on the cores with the smallest next start time
		\EndIf
	\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

\section{Working with a real workload and cluster\todo[inline]{Max: Find a better name}}\label{sec.working}
Actual workloads at HPC resources shared by a great number of users with diverse needs can contain structures
that are non-trivial to replicate in a fully artificial simulted job pattern. We believe that this is especially
true for data-dependent patterns, where a project might launch a burst of jobs using the same file just a few thousand
core hours in length, then be quiet for a long time processing the results, and then launch another such burst.

On the other hand, it would be disruptive to expose a real user community to a wide variety of experimental scheduling strategies.

For this reason, we used logs of historical submitted jobs, in terms of their exact submission time, size, stated runtime, and actual runtime.
Since explicit data dependencies are not encoded in Slurm job specifications, we created an artificial pattern for this. \todo[inline]{Carl: Max, please elaborate}

\todo[inline]{Elisabeth: I think we should say Rackham so that readers can checkout the hardware, but perhaps it should be fully blind as a starting point.}
The resource consists of 486 nodes with 20 cores each, with most of them having 128GB of RAM, with some 256GB and 512GB nodes.
The utilization levels are typically high (>90\%), but
not fully consistently so. The vast majority of jobs on this resources are single node jobs, even sometimes single core jobs. Run times
could extent to up to 10 days, while some jobs only last a few minutes. We do not claim that this is an ideal job submission strategy,
but rather it is an empirical observation of an actual user community including, but not exlusively consisting of, many subfields of the life sciences
with highly data-dependent workflows.

\section{Evaluations}\label{sec.evaluations}

\section{Conclusion}\label{sec.conclusion}

\todo[inline]{Max: 
Some schedulers do fairness as well with slurm or advance reservation with limitations (OAR).
We can tune our algorithms to do that as well.
Improve score to be efficient in any situation, any workload.
Improve mixed strategy to do more locality.}

\bibliographystyle{IEEEtran}
\bibliography{ref.bib}
\end{document}
